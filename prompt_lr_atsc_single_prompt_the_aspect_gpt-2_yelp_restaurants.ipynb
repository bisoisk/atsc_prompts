{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Google Colab use only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd '/content/drive/My Drive/cs696ds_lexalytics/Prompting Experiments'\n",
    "    \n",
    "    # Install packages specified in requirements\n",
    "    !pip install -r requirements.txt\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# We will use the following string ID to identify this particular (training) experiments\n",
    "# in directory paths and other settings\n",
    "experiment_id = 'prompt_lr_atsc_single_prompt_the_aspect_gpt-2_yelp_restaurants'\n",
    "\n",
    "# Random seed\n",
    "random_seed = 696\n",
    "\n",
    "# path to pretrained MLM model folder or the string \"gpt2\"\n",
    "lm_model_path = 'progress/lm_further_pretraining_gpt-2_yelp_restaurants_bseoh_2021-03-07--09_59_39/results/checkpoint-363156'\n",
    "\n",
    "# Proportion to be reserved for validation\n",
    "validation_dataset_proportion = 0.2\n",
    "\n",
    "# Prompts to be added to the end of each review text\n",
    "sentiment_prompts = [\n",
    "    \" The {aspect} is \"]\n",
    "\n",
    "# Training settings for logistic regression head\n",
    "training_epochs = 10\n",
    "training_batch_size = 32\n",
    "training_learning_rate = 1e-3\n",
    "training_weight_decay = 0.01\n",
    "\n",
    "validation_batch_size = 32\n",
    "testing_batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "# Random seed settings\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Print version information\n",
    "print(\"Python version: \" + sys.version)\n",
    "print(\"NumPy version: \" + np.__version__)\n",
    "print(\"PyTorch version: \" + torch.__version__)\n",
    "print(\"Transformers version: \" + transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    torch_device = torch.device('cuda')\n",
    "\n",
    "    # Set this to True to make your output immediately reproducible\n",
    "    # Note: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    \n",
    "    # Disable 'benchmark' mode: Set this False if you want to measure running times more fairly\n",
    "    # Note: https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # Faster Host to GPU copies with page-locked memory\n",
    "    use_pin_memory = True\n",
    "    \n",
    "    # Number of compute devices to be used for training\n",
    "    training_device_count = torch.cuda.device_count()\n",
    "\n",
    "    # CUDA libraries version information\n",
    "    print(\"CUDA Version: \" + str(torch.version.cuda))\n",
    "    print(\"cuDNN Version: \" + str(torch.backends.cudnn.version()))\n",
    "    print(\"CUDA Device Name: \" + str(torch.cuda.get_device_name()))\n",
    "    print(\"CUDA Capabilities: \"+ str(torch.cuda.get_device_capability()))\n",
    "    print(\"Number of CUDA devices: \"+ str(training_device_count))\n",
    "    \n",
    "else:\n",
    "    torch_device = torch.device('cpu')\n",
    "    use_pin_memory = False\n",
    "    \n",
    "    # Number of compute devices to be used for training\n",
    "    training_device_count = 1\n",
    "\n",
    "print()\n",
    "print(\"PyTorch device selected:\", torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Datasets for Prompt-based Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the SemEval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load semeval for both domains\n",
    "in_domain_semeval_dataset = datasets.load_dataset(\n",
    "    os.path.abspath('dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
    "    data_files={\n",
    "        'test': 'dataset_files/semeval_2014/Restaurants_Test_Gold.xml',\n",
    "        'train': 'dataset_files/semeval_2014/Restaurants_Train_v2.xml',\n",
    "    },\n",
    "    cache_dir='dataset_cache')\n",
    "\n",
    "out_domain_semeval_dataset = datasets.load_dataset(\n",
    "    os.path.abspath('dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
    "    data_files={\n",
    "        'test': 'dataset_files/semeval_2014/Laptops_Test_Gold.xml',\n",
    "        'train': 'dataset_files/semeval_2014/Laptop_Train_v2.xml',\n",
    "    },\n",
    "    cache_dir='dataset_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_domain_train = out_domain_semeval_dataset['train']\n",
    "out_domain_test = out_domain_semeval_dataset['test']\n",
    "\n",
    "in_domain_test = in_domain_semeval_dataset['test'] # Never use in-domain training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-validation split for out-domain SemEval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set size after validation split\n",
    "new_out_domain_train_dataset_size = int(len(out_domain_train) * (1 - validation_dataset_proportion))\n",
    "new_out_domain_valid_dataset_size = len(out_domain_train) - new_out_domain_train_dataset_size\n",
    "\n",
    "print(\"Training dataset (out-domain) after split:\", new_out_domain_train_dataset_size)\n",
    "print(\"Validation dataset (out-domain) after split:\", new_out_domain_valid_dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_domain_train = out_domain_train.shuffle(seed=random_seed)\n",
    "\n",
    "new_out_domain_train_dataset = out_domain_train.select(\n",
    "    indices=np.arange(new_out_domain_train_dataset_size))\n",
    "\n",
    "new_out_domain_valid_dataset = out_domain_train.select(\n",
    "    indices=np.arange(\n",
    "        new_out_domain_train_dataset_size,\n",
    "        new_out_domain_train_dataset_size + new_out_domain_valid_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_out_domain_train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot ATSC with Prompts + Logistic Regression Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pretrained LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained language model\n",
    "lm = transformers.AutoModelForCausalLM.from_pretrained(lm_model_path)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2', cache_dir='gpt2_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the GPT-2 layers\n",
    "for param in lm.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "lm.config.pad_token_id = lm.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a new model with logistic regression head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = utils.MultiPromptSentimentClassificationHead(\n",
    "    lm=lm,\n",
    "    num_class=3, num_prompts=len(sentiment_prompts))\n",
    "\n",
    "classifier_model = classifier_model.to(device=torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recheck whether the CLM is frozen\n",
    "for param in classifier_model.lm.parameters():\n",
    "    assert param.requires_grad == False\n",
    "    \n",
    "# classifier_model.linear should be trainable\n",
    "for param in classifier_model.linear.parameters():\n",
    "    assert param.requires_grad == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    new_out_domain_train_dataset, batch_size=training_batch_size,\n",
    "    pin_memory=use_pin_memory)\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    new_out_domain_valid_dataset, batch_size=validation_batch_size,\n",
    "    pin_memory=use_pin_memory)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = transformers.AdamW(\n",
    "    classifier_model.parameters(),\n",
    "    lr=training_learning_rate,\n",
    "    weight_decay=training_weight_decay)\n",
    "\n",
    "scheduler = transformers.get_constant_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0)\n",
    "\n",
    "# The directory to save the best version of the head\n",
    "trained_model_directory = os.path.join('.', 'trained_models', experiment_id)\n",
    "\n",
    "shutil.rmtree(trained_model_directory, ignore_errors=True)\n",
    "os.makedirs(trained_model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, labels):\n",
    "    preds = predictions.argmax(-1)\n",
    "\n",
    "    precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
    "        y_true=labels, y_pred=preds, labels=[0,1,2], average='macro')\n",
    "\n",
    "    acc = sklearn.metrics.accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_validation_loss = float('inf')\n",
    "best_epoch = -1\n",
    "\n",
    "for epoch in tqdm.notebook.tqdm(range(int(training_epochs))):\n",
    "\n",
    "    print(\"Training epoch %d\" % epoch)\n",
    "    print()\n",
    "\n",
    "    classifier_model.train()\n",
    "\n",
    "    for batch in tqdm.notebook.tqdm(train_dataloader):\n",
    "\n",
    "        batch_encoded = []\n",
    "\n",
    "        for prompt in sentiment_prompts:\n",
    "            for i in range(len(batch['text'])):\n",
    "                encoded = tokenizer(\n",
    "                    batch['text'][i], prompt.format(aspect=batch['aspect'][i]),\n",
    "                    truncation='only_first', max_length=256,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "\n",
    "                encoded = encoded.to(torch_device)\n",
    "\n",
    "                batch_encoded.append(encoded)\n",
    "\n",
    "        batch_label = batch[\"sentiment\"]\n",
    "        batch_label = batch_label.to(torch_device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_output = classifier_model(batch_encoded)\n",
    "        \n",
    "        loss = loss_function(batch_output, batch_label)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Validate the model using val dataset\n",
    "    with torch.no_grad():\n",
    "        classifier_model.eval()\n",
    "\n",
    "        print(\"Validation epoch %d\" % epoch)\n",
    "        print()\n",
    "\n",
    "        predictions_val = torch.Tensor()\n",
    "        labels_val = torch.Tensor()\n",
    "\n",
    "        for batch_val in tqdm.notebook.tqdm(validation_dataloader):\n",
    "\n",
    "            batch_val_encoded = []\n",
    "\n",
    "            for prompt in sentiment_prompts:\n",
    "                for i in range(len(batch_val['text'])):\n",
    "                    encoded = tokenizer(\n",
    "                        batch_val['text'][i], prompt.format(aspect=batch_val['aspect'][i]),\n",
    "                        truncation='only_first', max_length=256,\n",
    "                        return_tensors='pt'\n",
    "                    )\n",
    "\n",
    "                    encoded = encoded.to(torch_device)\n",
    "\n",
    "                    batch_val_encoded.append(encoded)\n",
    "\n",
    "            batch_val_label = batch_val[\"sentiment\"]\n",
    "\n",
    "            batch_val_output = classifier_model(batch_val_encoded)\n",
    "\n",
    "            batch_val_output = batch_val_output.to('cpu')\n",
    "\n",
    "            predictions_val = torch.cat([predictions_val, batch_val_output])\n",
    "            labels_val = torch.cat([labels_val, batch_val_label])\n",
    "\n",
    "        # Compute metrics\n",
    "        validation_loss = torch.nn.functional.cross_entropy(predictions_val, labels_val.long())\n",
    "        validation_metrics = compute_metrics(predictions_val, labels_val)\n",
    "\n",
    "        print(\n",
    "            \"Epoch {}, Training Loss: {}, Validation Loss: {}, Validation Metrics: {}\".format(epoch, loss.item(), validation_loss.item(), validation_metrics))\n",
    "        print()\n",
    "\n",
    "        # Save the current epoch's model if the validation loss is lower than the best known so far\n",
    "        if validation_loss.item() < best_validation_loss:\n",
    "\n",
    "            if best_epoch != -1:\n",
    "                try:\n",
    "                    os.remove(os.path.join(trained_model_directory, 'epoch_{}.pt'.format(best_epoch)))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            best_validation_loss = validation_loss.item()\n",
    "            best_epoch = epoch\n",
    "            torch.save(classifier_model.linear, os.path.join(trained_model_directory, 'epoch_{}.pt'.format(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation with in-domain test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    in_domain_test, batch_size=testing_batch_size,\n",
    "    pin_memory=use_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best found head weights\n",
    "with torch.no_grad():\n",
    "    classifier_model.linear = torch.load(\n",
    "        os.path.join(trained_model_directory, 'epoch_{}.pt'.format(best_epoch)),\n",
    "        map_location=torch_device)\n",
    "\n",
    "    classifier_model.eval()\n",
    "\n",
    "    predictions_test = torch.Tensor()\n",
    "    labels_test = torch.Tensor()\n",
    "\n",
    "    for batch_test in tqdm.notebook.tqdm(test_dataloader):\n",
    "\n",
    "        batch_test_encoded = []\n",
    "\n",
    "        for prompt in sentiment_prompts:\n",
    "            for i in range(len(batch_test['text'])):\n",
    "                encoded = tokenizer(\n",
    "                    batch_test['text'][i], prompt.format(aspect=batch_test['aspect'][i]),\n",
    "                    truncation='only_first', max_length=256,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "\n",
    "                encoded = encoded.to(torch_device)\n",
    "\n",
    "                batch_test_encoded.append(encoded)\n",
    "\n",
    "        batch_test_label = batch_test[\"sentiment\"]\n",
    "\n",
    "        batch_test_output = classifier_model(batch_test_encoded)\n",
    "\n",
    "        batch_test_output = batch_test_output.to('cpu')\n",
    "\n",
    "        predictions_test = torch.cat([predictions_test, batch_test_output])\n",
    "        labels_test = torch.cat([labels_test, batch_test_label])\n",
    "\n",
    "    # Compute metrics\n",
    "    test_metrics = compute_metrics(predictions_test, labels_test)\n",
    "\n",
    "    print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics and confusion matrix based upon predictions and true labels\n",
    "cm = sklearn.metrics.confusion_matrix(labels_test.detach().numpy(), predictions_test.detach().numpy().argmax(-1))\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[i for i in [\"positive\", \"negative\", \"neutral\"]],\n",
    "    columns=[i for i in [\"positive\", \"negative\", \"neutral\"]])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "ax = sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "prompt_lr_atsc_single_prompt_the_aspect_gpt-2_yelp_restaurants.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "131cf939d0c14bf3a308a951ef737d0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "  3%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee26c18a75794649962098c794ce2001",
      "max": 58,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8e8a11c6971475896c88f1c9acb006e",
      "value": 2
     }
    },
    "27ae4d0ce5c8447a9a22505833a07a8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bfd55b743524fd58fbbb4c3e132f97c",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6f0d313157c4594805366296c3e3be2",
      "value": 0
     }
    },
    "328aa9ac1a424ea5a635a8b0c5660fc7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39dfac33c46b432786e543ffbde2417b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c628cd7274d84b75af59c2f4e6224688",
      "placeholder": "​",
      "style": "IPY_MODEL_4bba50658f124d2f985d07ec2c55722a",
      "value": " 0/10 [00:00&lt;?, ?it/s]"
     }
    },
    "4bba50658f124d2f985d07ec2c55722a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5abe3ead0b1e435889bf7dbc3fa879f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ad108268209474b9e3d739ea32250fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_131cf939d0c14bf3a308a951ef737d0a",
       "IPY_MODEL_f18b9030bea245b882076597843a46d2"
      ],
      "layout": "IPY_MODEL_328aa9ac1a424ea5a635a8b0c5660fc7"
     }
    },
    "9bfd55b743524fd58fbbb4c3e132f97c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6f0d313157c4594805366296c3e3be2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c628cd7274d84b75af59c2f4e6224688": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c825c141e8d24f0fa7f1743e01e56c79": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d56341828b264468ad288e0251abbb29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27ae4d0ce5c8447a9a22505833a07a8b",
       "IPY_MODEL_39dfac33c46b432786e543ffbde2417b"
      ],
      "layout": "IPY_MODEL_f8f38f3ef6fd47609eef585b5f25e5e3"
     }
    },
    "e8e8a11c6971475896c88f1c9acb006e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ee26c18a75794649962098c794ce2001": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f18b9030bea245b882076597843a46d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c825c141e8d24f0fa7f1743e01e56c79",
      "placeholder": "​",
      "style": "IPY_MODEL_5abe3ead0b1e435889bf7dbc3fa879f5",
      "value": " 2/58 [00:00&lt;00:25,  2.17it/s]"
     }
    },
    "f8f38f3ef6fd47609eef585b5f25e5e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
