{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Tags",
    "colab": {
      "name": "nli_few_shot_in_domain_laptops_16_MNLI-base_the_aspect_is_696",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "nteract": {
      "version": "0.28.0"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4131.042453,
      "end_time": "2021-04-14T10:26:33.868071",
      "environment_variables": {},
      "exception": null,
      "input_path": "nli_experiment_template.ipynb",
      "output_path": "results_nli_supervised_in_domain_laptops/nli_supervised_in_domain_laptops_MNLI-base_I_felt_696.ipynb",
      "parameters": {
        "experiment_id": "nli_supervised_in_domain_laptops_MNLI-base_I_felt_696",
        "neg_prompt_indexes": [
          1
        ],
        "nli_model_path": "textattack/bert-base-uncased-MNLI",
        "pos_prompt_indexes": [
          0
        ],
        "random_seed": 696,
        "sentiment_prompts": [
          "I felt the {aspect} was good.",
          "I felt the {aspect} was bad."
        ],
        "testing_batch_size": 8,
        "testing_domain": "laptops",
        "training_batch_size": 8,
        "training_domain": "laptops"
      },
      "start_time": "2021-04-14T09:17:42.825618",
      "version": "2.3.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03fbf0400e5e46a696c9e53381f8b321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a93ecb5641c44108955da056720b345",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b0c9e05ebaab439e988b390d5d7ca570",
              "IPY_MODEL_ac68c6d3f7aa4b00b4bbb9e16287b8f7"
            ]
          }
        },
        "3a93ecb5641c44108955da056720b345": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0c9e05ebaab439e988b390d5d7ca570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cdeb1d59e2404baaa302bd8e52bb908e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 80,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 80,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63cdb7539d1e40708f34387e340c3be5"
          }
        },
        "ac68c6d3f7aa4b00b4bbb9e16287b8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_16090bf951a94040a08cdca6636c8142",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 80/80 [00:43&lt;00:00,  1.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3fe604cc168d40eb90cc6ffc245c5474"
          }
        },
        "cdeb1d59e2404baaa302bd8e52bb908e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63cdb7539d1e40708f34387e340c3be5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16090bf951a94040a08cdca6636c8142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3fe604cc168d40eb90cc6ffc245c5474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYSFmGrp2wSp"
      },
      "source": [
        ""
      ],
      "id": "yYSFmGrp2wSp",
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvZa9Z3V2eGK"
      },
      "source": [
        ""
      ],
      "id": "NvZa9Z3V2eGK",
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2dd8e3a",
        "papermill": {
          "duration": 0.099569,
          "end_time": "2021-04-14T09:17:44.356246",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.256677",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Initial Setups"
      ],
      "id": "b2dd8e3a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09036ef8",
        "papermill": {
          "duration": 0.070817,
          "end_time": "2021-04-14T09:17:44.498175",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.427358",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## (Google Colab use only)"
      ],
      "id": "09036ef8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:44.656950Z",
          "iopub.status.busy": "2021-04-14T09:17:44.656291Z",
          "iopub.status.idle": "2021-04-14T09:17:44.660609Z",
          "shell.execute_reply": "2021-04-14T09:17:44.660079Z"
        },
        "id": "1e81b28a",
        "papermill": {
          "duration": 0.091994,
          "end_time": "2021-04-14T09:17:44.660753",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.568759",
          "status": "completed"
        },
        "tags": [],
        "outputId": "ae92bedc-8499-4eca-efc5-2e373713b88c"
      },
      "source": [
        "# Use Google Colab\n",
        "use_colab = True\n",
        "\n",
        "# Is this notebook running on Colab?\n",
        "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
        "# should be available in this environment\n",
        "\n",
        "# Previous version used importlib, but we could do the same thing with\n",
        "# just attempting to import google.colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    colab_available = True\n",
        "except:\n",
        "    colab_available = False\n",
        "\n",
        "if use_colab and colab_available:\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # cd to the appropriate working directory under my Google Drive\n",
        "    %cd '/content/drive/My Drive/ATSC'\n",
        "    \n",
        "    # Install packages specified in requirements\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # List the directory contents\n",
        "    !ls"
      ],
      "id": "1e81b28a",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/ATSC\n",
            "Requirement already satisfied: transformers==4.3.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (4.3.3)\n",
            "Requirement already satisfied: datasets==1.2.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.2.1)\n",
            "Requirement already satisfied: pytokenizations==0.7.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.7.2)\n",
            "Requirement already satisfied: spacy==2.3.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.3.5)\n",
            "Requirement already satisfied: en_core_web_sm from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.2.5)\n",
            "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.7.1)\n",
            "Requirement already satisfied: scikit-learn==0.24.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.24.1)\n",
            "Requirement already satisfied: seaborn==0.11.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (4.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (0.10.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (0.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (1.1.5)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (0.70.11.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (56.1.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (3.0.5)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (7.4.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->-r requirements.txt (line 6)) (3.7.4.3)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 7)) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.11.1->-r requirements.txt (line 8)) (3.2.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.3.3->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3->-r requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1->-r requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1->-r requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn==0.11.1->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn==0.11.1->-r requirements.txt (line 8)) (0.10.0)\n",
            " apex-master.zip\n",
            " baseline\n",
            " bert_base_cache\n",
            " checkpoint-1210520\n",
            " checkpoint-553363.zip\n",
            " dataset_cache\n",
            "'dataset_cache (1)'\n",
            " dataset_files\n",
            " dataset_scripts\n",
            " GPT2\n",
            " gpt2_amazon\n",
            " gpt2_cache\n",
            " MLM\n",
            " NLI\n",
            " nli-checkpoint-epoch2\n",
            " nli_files.txt\n",
            " NLIResults\n",
            " prompt_lr_atsc_single_prompt_the_aspect_gpt-2_yelp_restaurants\n",
            " requirements.txt\n",
            " semeval_data_files\n",
            " smart_mlm_yelp_500k_15percent.ipynb\n",
            " utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b2be680",
        "papermill": {
          "duration": 0.071744,
          "end_time": "2021-04-14T09:17:44.804138",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.732394",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Experiment parameters"
      ],
      "id": "8b2be680"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIpbwIm11WT-"
      },
      "source": [
        "import torch\n",
        "class SinglePromptLogitSentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, lm, num_class, pseudo_label_words, target_token_id=-1):\n",
        "        super(SinglePromptLogitSentimentClassificationHead, self).__init__()\n",
        "\n",
        "        self.num_class = num_class\n",
        "        self.pseudo_label_words = pseudo_label_words\n",
        "        self.target_token_id = target_token_id\n",
        "\n",
        "        self.lm = lm\n",
        "        \n",
        "        # Is self.lm BERT or GPT-2?\n",
        "        if self.lm.config.architectures[0].startswith('Bert'):\n",
        "            # if self.lm is BERT, then mask_token_id should be specified\n",
        "            assert self.target_token_id != -1\n",
        "            self.lm_type = 'bert'\n",
        "        elif self.lm.config.architectures[0].startswith('GPT2'):\n",
        "            self.lm_type = 'gpt2'\n",
        "        else:\n",
        "            raise Exception('Unsupported language model type.')\n",
        "            \n",
        "        print(\"Detected LM type:\", self.lm_type)\n",
        "\n",
        "    def forward(self, reviews_and_prompts):\n",
        "\n",
        "        if self.lm_type == 'bert':\n",
        "            # Figures out where the mask token was placed\n",
        "            target_indexes = (reviews_and_prompts.data[\"input_ids\"] == self.target_token_id)\n",
        "\n",
        "            lm_outputs = self.lm(**reviews_and_prompts)\n",
        "\n",
        "            outputs = lm_outputs.logits[target_indexes]\n",
        "        \n",
        "            outputs = outputs[:, self.pseudo_label_words]\n",
        "            \n",
        "        elif self.lm_type == 'gpt2':\n",
        "            \n",
        "            outputs = []\n",
        "            \n",
        "            for example in reviews_and_prompts:\n",
        "                lm_outputs = self.lm(**example, return_dict=True)\n",
        "                \n",
        "                lm_predictions = lm_outputs.logits[0, len(example['input_ids'][0]) - 1, self.pseudo_label_words]\n",
        "                \n",
        "                outputs.append(lm_predictions)\n",
        "\n",
        "            outputs = torch.stack(outputs, dim=0)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class MultiPromptSentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, lm, num_class, num_prompts, target_token_id=-1):\n",
        "        super(MultiPromptSentimentClassificationHead, self).__init__()\n",
        "\n",
        "        self.num_class = num_class\n",
        "        self.num_prompts = num_prompts\n",
        "        self.target_token_id = target_token_id\n",
        "\n",
        "        self.lm = lm\n",
        "        \n",
        "        # Is self.lm BERT or GPT-2?\n",
        "        if self.lm.config.architectures[0].startswith('Bert'):\n",
        "            # if self.lm is BERT, then mask_token_id should be specified\n",
        "            assert self.target_token_id != -1\n",
        "            self.lm_type = 'bert'\n",
        "        elif self.lm.config.architectures[0].startswith('GPT2'):\n",
        "            self.lm_type = 'gpt2'\n",
        "        else:\n",
        "            raise Exception('Unsupported language model type.')\n",
        "\n",
        "        print(\"Detected LM type:\", self.lm_type)\n",
        "\n",
        "        # Linear layer\n",
        "        self.linear = torch.nn.Linear(\n",
        "            self.num_prompts * self.lm.config.hidden_size, self.num_class)\n",
        "\n",
        "    def forward(self, reviews_and_prompts):\n",
        "\n",
        "        # Extract hidden states and feed them to self.linear\n",
        "        outputs = []\n",
        "\n",
        "        lr_inputs_batch = []\n",
        "\n",
        "        # Figures out where the mask token was placed\n",
        "        if self.lm_type == 'bert':\n",
        "            # For BERT, we need to find the token in each input with [MASK]\n",
        "            target_indexes = torch.nonzero(\n",
        "                reviews_and_prompts.data[\"input_ids\"] == self.target_token_id)[:, 1]\n",
        "\n",
        "            lm_outputs = self.lm(**reviews_and_prompts, output_hidden_states=True)\n",
        "\n",
        "            real_batch_size = len(reviews_and_prompts.data[\"input_ids\"]) // self.num_prompts\n",
        "\n",
        "        elif self.lm_type == 'gpt2':\n",
        "            lm_outputs = []\n",
        "            target_indexes = []\n",
        "\n",
        "            # For GPT-2, we need to find the spot right after the input text\n",
        "            for example in reviews_and_prompts:\n",
        "                target_indexes.append(len(example['input_ids'][0]) - 1)\n",
        "\n",
        "                lm_outputs.append(self.lm(**example, output_hidden_states=True))\n",
        "\n",
        "            real_batch_size = len(reviews_and_prompts) // self.num_prompts\n",
        "                \n",
        "        for i in range(real_batch_size):\n",
        "            # Create an input to self.linear by\n",
        "            # concatenating last hidden states for this review\n",
        "            lr_input = []\n",
        "\n",
        "            for j in range(self.num_prompts):\n",
        "                if self.lm_type == 'bert':\n",
        "                    lr_input.append(lm_outputs[\"hidden_states\"][-1][i+real_batch_size*j][target_indexes[i+real_batch_size*j]])\n",
        "                elif self.lm_type == 'gpt2':\n",
        "                    lr_input.append(lm_outputs[i+real_batch_size*j][\"hidden_states\"][-1][0][target_indexes[i+real_batch_size*j]])\n",
        "                    \n",
        "            lr_input = torch.cat(lr_input, dim=0)\n",
        "\n",
        "            lr_inputs_batch.append(lr_input)\n",
        "\n",
        "        lr_inputs_batch = torch.stack(lr_inputs_batch)\n",
        "\n",
        "        outputs = self.linear(lr_inputs_batch)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class NoPromptSentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, lm, num_class):\n",
        "        super(NoPromptSentimentClassificationHead, self).__init__()\n",
        "\n",
        "        self.num_class = num_class\n",
        "\n",
        "        self.lm = lm\n",
        "\n",
        "        self.linear = torch.nn.Linear(\n",
        "            self.lm.config.hidden_size, self.num_class)\n",
        "\n",
        "    def forward(self, reviews_and_prompts):\n",
        "\n",
        "        lm_outputs = self.lm(**reviews_and_prompts, output_hidden_states=True)\n",
        "\n",
        "        # Last hidden state for [CLS] token\n",
        "        last_hidden_state_cls = lm_outputs[\"hidden_states\"][-1][:, 0, :]\n",
        "        \n",
        "        outputs = self.linear(last_hidden_state_cls)\n",
        "\n",
        "        return outputs\n",
        "    \n",
        "class NLISentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, nli_model, num_prompts, pos_prompt_indexes, neg_prompt_indexes):\n",
        "        super(NLISentimentClassificationHead, self).__init__()\n",
        "        \n",
        "        self.num_prompts = num_prompts\n",
        "        self.nli_model = nli_model\n",
        "        \n",
        "        self.pos_prompt_indexes = pos_prompt_indexes\n",
        "        self.neg_prompt_indexes = neg_prompt_indexes\n",
        "        \n",
        "    def forward(self, reviews_and_prompts):\n",
        "        \n",
        "        nli_output = self.nli_model(**reviews_and_prompts)[\"logits\"]\n",
        "\n",
        "        outputs = torch.Tensor().to(self.nli_model.device)\n",
        "\n",
        "        # Text Attack NLI Labels: 0-> Contradiction, 1-> Entailment, 2-> Neutral\n",
        "        # Sentiment Polarity Labels: 0-> Positive, 1-> Negative, 2-> Neutral\n",
        "        for i in range(len(nli_output)//self.num_prompts):\n",
        "            prompts_batch = nli_output[i*self.num_prompts:(i+1)*self.num_prompts]\n",
        "\n",
        "            pos_logit = torch.mean(prompts_batch[self.pos_prompt_indexes], dim=0)[1]\n",
        "\n",
        "            neg_logit = torch.mean(prompts_batch[self.neg_prompt_indexes], dim=0)[1]\n",
        "\n",
        "            neu_logit = torch.mean(prompts_batch, dim=0)[2]\n",
        "\n",
        "            pred_logits = torch.stack([pos_logit, neg_logit, neu_logit])\n",
        "            pred_logits = torch.reshape(pred_logits, (1,-1))\n",
        "\n",
        "            outputs = torch.cat([outputs, pred_logits])\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class NLIMinSentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, nli_model, num_prompts, pos_prompt_indexes, neg_prompt_indexes):\n",
        "        super(NLIMinSentimentClassificationHead, self).__init__()\n",
        "        \n",
        "        self.num_prompts = num_prompts\n",
        "        self.nli_model = nli_model\n",
        "        \n",
        "        self.pos_prompt_indexes = pos_prompt_indexes\n",
        "        self.neg_prompt_indexes = neg_prompt_indexes\n",
        "        \n",
        "    def forward(self, reviews_and_prompts):\n",
        "        \n",
        "        nli_output = self.nli_model(**reviews_and_prompts)[\"logits\"]\n",
        "\n",
        "        outputs = torch.Tensor().to(self.nli_model.device)\n",
        "\n",
        "        # Text Attack NLI Labels: 0-> Contradiction, 1-> Entailment, 2-> Neutral\n",
        "        # Sentiment Polarity Labels: 0-> Positive, 1-> Negative, 2-> Neutral\n",
        "        for i in range(len(nli_output)//self.num_prompts):\n",
        "            prompts_batch = nli_output[i*self.num_prompts:(i+1)*self.num_prompts]\n",
        "\n",
        "            pos_logit = torch.mean(prompts_batch[self.pos_prompt_indexes], dim=0)[1]\n",
        "\n",
        "            neg_logit = torch.mean(prompts_batch[self.neg_prompt_indexes], dim=0)[1]\n",
        "\n",
        "            neu_logit = torch.min(prompts_batch, dim=0)[0][2]\n",
        "\n",
        "            pred_logits = torch.stack([pos_logit, neg_logit, neu_logit])\n",
        "            pred_logits = torch.reshape(pred_logits, (1,-1))\n",
        "\n",
        "            outputs = torch.cat([outputs, pred_logits])\n",
        "\n",
        "        return outputs\n"
      ],
      "id": "DIpbwIm11WT-",
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:44.957547Z",
          "iopub.status.busy": "2021-04-14T09:17:44.956864Z",
          "iopub.status.idle": "2021-04-14T09:17:44.960465Z",
          "shell.execute_reply": "2021-04-14T09:17:44.959837Z"
        },
        "id": "205c591d",
        "papermill": {
          "duration": 0.084988,
          "end_time": "2021-04-14T09:17:44.960595",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.875607",
          "status": "completed"
        },
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "\n",
        "# We will use the following string ID to identify this particular (training) experiments\n",
        "# in directory paths and other settings\n",
        "experiment_id = 'supervised_nli_single_prompt_1_in_domain_restaurant_MNLI_base_seed_696'\n",
        "\n",
        "# Random seed\n",
        "random_seed = 696\n",
        "\n",
        "# path to pretrained nli model folder or the string \"textattack/bert-base-uncased-MNLI\"\n",
        "nli_model_path = \"textattack/bert-base-uncased-MNLI\"\n",
        "\n",
        "# Prompts to be added to the end of each review text\n",
        "sentiment_prompts = [\n",
        "    \"The {aspect} is good.\",\n",
        "    \"The {aspect} is bad.\"]\n",
        "\n",
        "#index of the prompts in the sentiment_prompts by polarity for later grouping\n",
        "pos_prompt_indexes = [0]\n",
        "neg_prompt_indexes = [1]\n",
        "\n",
        "#What datasets to be used for training and testing loops\n",
        "training_domain = \"restaurants\"\n",
        "testing_domain = \"restaurants\"\n",
        "\n",
        "# Training settings\n",
        "training_epochs = 20\n",
        "training_batch_size = 8\n",
        "training_learning_rate = 2e-5\n",
        "training_weight_decay = 0.01\n",
        "training_warmup_steps_duration = 0.1\n",
        "training_best_model_criterion = 'train_loss'\n",
        "\n",
        "training_lm_freeze = False\n",
        "\n",
        "validation_enabled = False\n",
        "validation_dataset_proportion = 0.2\n",
        "validation_batch_size = 8\n",
        "\n",
        "testing_batch_size = 32"
      ],
      "id": "205c591d",
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:45.125761Z",
          "iopub.status.busy": "2021-04-14T09:17:45.125025Z",
          "iopub.status.idle": "2021-04-14T09:17:45.128050Z",
          "shell.execute_reply": "2021-04-14T09:17:45.127424Z"
        },
        "papermill": {
          "duration": 0.08669,
          "end_time": "2021-04-14T09:17:45.128255",
          "exception": false,
          "start_time": "2021-04-14T09:17:45.041565",
          "status": "completed"
        },
        "tags": [
          "injected-parameters"
        ],
        "id": "33158748"
      },
      "source": [
        "# Parameters\n",
        "experiment_id = \"nli_few_shot_in_domain_laptops_16_MNLI-base_the_aspect_is_696\"\n",
        "random_seed = 696\n",
        "nli_model_path = \"textattack/bert-base-uncased-MNLI\"\n",
        "sentiment_prompts = [\"The {aspect} are good.\", \"The {aspect} are bad.\"]\n",
        "pos_prompt_indexes = [0]\n",
        "neg_prompt_indexes = [1]\n",
        "training_domain = \"laptops\"\n",
        "testing_batch_size = 8\n",
        "testing_domain = \"laptops\"\n",
        "training_batch_size = 8\n",
        "sample_size = 64\n"
      ],
      "id": "33158748",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "169e034b",
        "papermill": {
          "duration": 0.059185,
          "end_time": "2021-04-14T09:17:45.258934",
          "exception": false,
          "start_time": "2021-04-14T09:17:45.199749",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Package imports"
      ],
      "id": "169e034b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:45.381681Z",
          "iopub.status.busy": "2021-04-14T09:17:45.381034Z",
          "iopub.status.idle": "2021-04-14T09:17:48.668262Z",
          "shell.execute_reply": "2021-04-14T09:17:48.669304Z"
        },
        "id": "18d534de",
        "papermill": {
          "duration": 3.355855,
          "end_time": "2021-04-14T09:17:48.669607",
          "exception": false,
          "start_time": "2021-04-14T09:17:45.313752",
          "status": "completed"
        },
        "tags": [],
        "outputId": "9f6e7e05-b855-41a5-faf2-44219e0df1f7"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import copy\n",
        "import inspect\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "import datasets\n",
        "import sklearn.metrics\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import tqdm\n",
        "\n",
        "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
        "parent_dir = os.path.dirname(current_dir)\n",
        "sys.path.append(parent_dir)\n",
        "\n",
        "import utils\n",
        "\n",
        "# Random seed settings\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "# cuBLAS reproducibility\n",
        "# https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
        "torch.set_deterministic(True)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# Print version information\n",
        "print(\"Python version: \" + sys.version)\n",
        "print(\"NumPy version: \" + np.__version__)\n",
        "print(\"PyTorch version: \" + torch.__version__)\n",
        "print(\"Transformers version: \" + transformers.__version__)"
      ],
      "id": "18d534de",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version: 3.7.10 (default, May  3 2021, 02:48:31) \n",
            "[GCC 7.5.0]\n",
            "NumPy version: 1.19.5\n",
            "PyTorch version: 1.7.1\n",
            "Transformers version: 4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78f1ee52",
        "papermill": {
          "duration": 0.067281,
          "end_time": "2021-04-14T09:17:48.839940",
          "exception": false,
          "start_time": "2021-04-14T09:17:48.772659",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## PyTorch GPU settings"
      ],
      "id": "78f1ee52"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:50.767583Z",
          "iopub.status.busy": "2021-04-14T09:17:49.016404Z",
          "iopub.status.idle": "2021-04-14T09:17:50.771850Z",
          "shell.execute_reply": "2021-04-14T09:17:50.772413Z"
        },
        "id": "53d9ba9a",
        "papermill": {
          "duration": 1.862641,
          "end_time": "2021-04-14T09:17:50.772589",
          "exception": false,
          "start_time": "2021-04-14T09:17:48.909948",
          "status": "completed"
        },
        "tags": [],
        "outputId": "cec5aafc-6e1f-4f4c-daa2-064657d88a45"
      },
      "source": [
        "\n",
        "if torch.cuda.is_available():    \n",
        "    torch_device = torch.device('cuda')\n",
        "\n",
        "    # Set this to True to make your output immediately reproducible\n",
        "    # Note: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "    # Disable 'benchmark' mode: Set this False if you want to measure running times more fairly\n",
        "    # Note: https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    \n",
        "    # Faster Host to GPU copies with page-locked memory\n",
        "    use_pin_memory = True\n",
        "    \n",
        "    # Number of compute devices to be used for training\n",
        "    training_device_count = torch.cuda.device_count()\n",
        "\n",
        "    # CUDA libraries version information\n",
        "    print(\"CUDA Version: \" + str(torch.version.cuda))\n",
        "    print(\"cuDNN Version: \" + str(torch.backends.cudnn.version()))\n",
        "    print(\"CUDA Device Name: \" + str(torch.cuda.get_device_name()))\n",
        "    print(\"CUDA Capabilities: \"+ str(torch.cuda.get_device_capability()))\n",
        "    print(\"Number of CUDA devices: \"+ str(training_device_count))\n",
        "    \n",
        "else:\n",
        "    torch_device = torch.device('cpu')\n",
        "    use_pin_memory = False\n",
        "    \n",
        "    # Number of compute devices to be used for training\n",
        "    training_device_count = 1\n",
        "\n",
        "print()\n",
        "print(\"PyTorch device selected:\", torch_device)"
      ],
      "id": "53d9ba9a",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Version: 10.2\n",
            "cuDNN Version: 7605\n",
            "CUDA Device Name: Tesla T4\n",
            "CUDA Capabilities: (7, 5)\n",
            "Number of CUDA devices: 1\n",
            "\n",
            "PyTorch device selected: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30f1f1cb",
        "papermill": {
          "duration": 0.072829,
          "end_time": "2021-04-14T09:17:50.920232",
          "exception": false,
          "start_time": "2021-04-14T09:17:50.847403",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Prepare Datasets for Prompt-based Classifier"
      ],
      "id": "30f1f1cb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b25dbc88",
        "papermill": {
          "duration": 0.072759,
          "end_time": "2021-04-14T09:17:51.066279",
          "exception": false,
          "start_time": "2021-04-14T09:17:50.993520",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Load the SemEval dataset"
      ],
      "id": "b25dbc88"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:51.227509Z",
          "iopub.status.busy": "2021-04-14T09:17:51.226811Z",
          "iopub.status.idle": "2021-04-14T09:17:51.948638Z",
          "shell.execute_reply": "2021-04-14T09:17:51.947637Z"
        },
        "id": "a4e71c29",
        "papermill": {
          "duration": 0.805682,
          "end_time": "2021-04-14T09:17:51.948940",
          "exception": false,
          "start_time": "2021-04-14T09:17:51.143258",
          "status": "completed"
        },
        "tags": [],
        "outputId": "ec4ede6a-d941-450c-c0de-3f4dff84efff"
      },
      "source": [
        "# Load semeval for both domains\n",
        "laptop_semeval_dataset = datasets.load_dataset(\n",
        "    os.path.abspath('./dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
        "    data_files={\n",
        "        'test': './dataset_files/semeval_2014/Laptops_Test_Gold.xml',\n",
        "        'train': './dataset_files/semeval_2014/Laptop_Train_v2.xml',\n",
        "    },\n",
        "    cache_dir='./dataset_cache')\n",
        "\n",
        "restaurant_semeval_dataset = datasets.load_dataset(\n",
        "    os.path.abspath('./dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
        "    data_files={\n",
        "        'test': './dataset_files/semeval_2014/Restaurants_Test_Gold.xml',\n",
        "        'train': './dataset_files/semeval_2014/Restaurants_Train_v2.xml',\n",
        "    },\n",
        "    cache_dir='./dataset_cache')"
      ],
      "id": "a4e71c29",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset sem_eval2014_task4_dataset (./dataset_cache/sem_eval2014_task4_dataset/default-2ba098669778f075/0.0.1/f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969)\n",
            "Using custom data configuration default\n",
            "Reusing dataset sem_eval2014_task4_dataset (./dataset_cache/sem_eval2014_task4_dataset/default-00707989ebea381d/0.0.1/f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.127349Z",
          "iopub.status.busy": "2021-04-14T09:17:52.126410Z",
          "iopub.status.idle": "2021-04-14T09:17:52.128934Z",
          "shell.execute_reply": "2021-04-14T09:17:52.129482Z"
        },
        "id": "234dcdac",
        "papermill": {
          "duration": 0.081917,
          "end_time": "2021-04-14T09:17:52.129628",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.047711",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "dataset_dic_train = {\n",
        "    \"laptops\": laptop_semeval_dataset['train'],\n",
        "    \"restaurants\": restaurant_semeval_dataset['train']\n",
        "}\n",
        "\n",
        "dataset_dic_test = {\n",
        "    \"laptops\": laptop_semeval_dataset['test'],\n",
        "    \"restaurants\": restaurant_semeval_dataset['test']\n",
        "}\n"
      ],
      "id": "234dcdac",
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.284055Z",
          "iopub.status.busy": "2021-04-14T09:17:52.283164Z",
          "iopub.status.idle": "2021-04-14T09:17:52.285775Z",
          "shell.execute_reply": "2021-04-14T09:17:52.286325Z"
        },
        "papermill": {
          "duration": 0.081159,
          "end_time": "2021-04-14T09:17:52.286474",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.205315",
          "status": "completed"
        },
        "tags": [],
        "id": "3b556c52"
      },
      "source": [
        "# The dataset chosen for training and testing\n",
        "train_set = dataset_dic_train[training_domain]\n",
        "test_set = dataset_dic_test[testing_domain]"
      ],
      "id": "3b556c52",
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42aeac01",
        "papermill": {
          "duration": 0.074267,
          "end_time": "2021-04-14T09:17:52.434905",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.360638",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Train-validation split"
      ],
      "id": "42aeac01"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.589122Z",
          "iopub.status.busy": "2021-04-14T09:17:52.588365Z",
          "iopub.status.idle": "2021-04-14T09:17:52.592239Z",
          "shell.execute_reply": "2021-04-14T09:17:52.591606Z"
        },
        "id": "c5201e50",
        "papermill": {
          "duration": 0.082863,
          "end_time": "2021-04-14T09:17:52.592369",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.509506",
          "status": "completed"
        },
        "tags": [],
        "outputId": "96823989-8723-4358-b5df-dc4310e7856f"
      },
      "source": [
        "# Training set size after validation split\n",
        "if validation_enabled:\n",
        "    new_train_dataset_size = int(len(train_set) * (1 - validation_dataset_proportion))\n",
        "    new_valid_dataset_size = len(train_set) - new_train_dataset_size\n",
        "    print(\"Training dataset after split:\", new_train_dataset_size)\n",
        "    print(\"Validation dataset after split:\", new_train_dataset_size)\n",
        "else:\n",
        "    new_train_dataset_size = len(train_set)\n",
        "    print(\"Training dataset size:\", new_train_dataset_size)"
      ],
      "id": "c5201e50",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset size: 2313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.730472Z",
          "iopub.status.busy": "2021-04-14T09:17:52.729971Z",
          "iopub.status.idle": "2021-04-14T09:17:52.787818Z",
          "shell.execute_reply": "2021-04-14T09:17:52.787292Z"
        },
        "id": "8710a9bd",
        "papermill": {
          "duration": 0.120927,
          "end_time": "2021-04-14T09:17:52.787955",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.667028",
          "status": "completed"
        },
        "tags": [],
        "outputId": "cd305b94-37c9-4cfb-c534-29bf2fba27ba"
      },
      "source": [
        "train_set = train_set.shuffle(seed=random_seed)\n",
        "\n",
        "new_train_set = train_set.select(indices=np.arange(new_train_dataset_size))\n",
        "\n",
        "if validation_enabled:\n",
        "    new_valid_set = train_set.select(\n",
        "        indices=np.arange(\n",
        "            new_train_dataset_size,\n",
        "            new_train_dataset_size + new_valid_dataset_size))"
      ],
      "id": "8710a9bd",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached shuffled indices for dataset at ./dataset_cache/sem_eval2014_task4_dataset/default-2ba098669778f075/0.0.1/f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969/cache-de8ce8ac91817d47.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.913145Z",
          "iopub.status.busy": "2021-04-14T09:17:52.912611Z",
          "iopub.status.idle": "2021-04-14T09:17:52.915730Z",
          "shell.execute_reply": "2021-04-14T09:17:52.915257Z"
        },
        "id": "60a082f3",
        "papermill": {
          "duration": 0.06474,
          "end_time": "2021-04-14T09:17:52.915829",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.851089",
          "status": "completed"
        },
        "tags": [],
        "outputId": "5045ca2e-fa5d-4a81-eec4-c388607f2e6b"
      },
      "source": [
        "print(new_train_set[0])"
      ],
      "id": "60a082f3",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'aspect': 'loads', 'sentiment': 2, 'text': 'Once I removed all the software the laptop loads in 15-20 seconds.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1865dbeb",
        "papermill": {
          "duration": 0.059399,
          "end_time": "2021-04-14T09:17:53.035203",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.975804",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Supervised ATSC with Prompts + Logistic Regression Head"
      ],
      "id": "1865dbeb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08dca259",
        "papermill": {
          "duration": 0.057453,
          "end_time": "2021-04-14T09:17:53.150677",
          "exception": false,
          "start_time": "2021-04-14T09:17:53.093224",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Load the pretrained LM"
      ],
      "id": "08dca259"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:53.270315Z",
          "iopub.status.busy": "2021-04-14T09:17:53.269643Z",
          "iopub.status.idle": "2021-04-14T09:17:58.431562Z",
          "shell.execute_reply": "2021-04-14T09:17:58.432583Z"
        },
        "id": "56a24d11",
        "papermill": {
          "duration": 5.224628,
          "end_time": "2021-04-14T09:17:58.432932",
          "exception": false,
          "start_time": "2021-04-14T09:17:53.208304",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Load pretrained language model\n",
        "nli_model = transformers.AutoModelForSequenceClassification.from_pretrained(nli_model_path)\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-MNLI\", cache_dir='../bert_base_cache')"
      ],
      "id": "56a24d11",
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:58.618927Z",
          "iopub.status.busy": "2021-04-14T09:17:58.618342Z",
          "iopub.status.idle": "2021-04-14T09:17:58.621535Z",
          "shell.execute_reply": "2021-04-14T09:17:58.621050Z"
        },
        "papermill": {
          "duration": 0.079367,
          "end_time": "2021-04-14T09:17:58.621647",
          "exception": false,
          "start_time": "2021-04-14T09:17:58.542280",
          "status": "completed"
        },
        "tags": [],
        "id": "3e1bfc3f"
      },
      "source": [
        "# Freeze all layers in lm.\n",
        "if training_lm_freeze:\n",
        "    for param in nli_model.parameters():\n",
        "        param.requires_grad = False"
      ],
      "id": "3e1bfc3f",
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:58.748044Z",
          "iopub.status.busy": "2021-04-14T09:17:58.747553Z",
          "iopub.status.idle": "2021-04-14T09:18:01.944791Z",
          "shell.execute_reply": "2021-04-14T09:18:01.945802Z"
        },
        "papermill": {
          "duration": 3.262784,
          "end_time": "2021-04-14T09:18:01.946086",
          "exception": false,
          "start_time": "2021-04-14T09:17:58.683302",
          "status": "completed"
        },
        "tags": [],
        "id": "c5220e7a"
      },
      "source": [
        "classifier = NLISentimentClassificationHead(\n",
        "                    nli_model = nli_model,\n",
        "                    num_prompts = len(sentiment_prompts),\n",
        "                    pos_prompt_indexes = pos_prompt_indexes,\n",
        "                    neg_prompt_indexes = neg_prompt_indexes\n",
        "                    )\n",
        "classifier_model = classifier.to(torch_device)"
      ],
      "id": "c5220e7a",
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72da7aad",
        "papermill": {
          "duration": 0.078495,
          "end_time": "2021-04-14T09:18:02.134812",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.056317",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training settings"
      ],
      "id": "72da7aad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:18:02.297951Z",
          "iopub.status.busy": "2021-04-14T09:18:02.297293Z",
          "iopub.status.idle": "2021-04-14T09:18:02.301372Z",
          "shell.execute_reply": "2021-04-14T09:18:02.301889Z"
        },
        "papermill": {
          "duration": 0.090522,
          "end_time": "2021-04-14T09:18:02.302042",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.211520",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af6620a2",
        "outputId": "6792e393-5de0-405c-a034-c4943f9469f4"
      },
      "source": [
        "# How many training steps would we have?\n",
        "approx_total_training_steps = len(new_train_set) // training_batch_size * training_epochs\n",
        "\n",
        "print(\"There will be approximately %d training steps.\" % approx_total_training_steps)\n",
        "\n",
        "# Let's have warmups for the first (training_warmup_steps_duration)% of steps.\n",
        "training_warmup_steps = int(approx_total_training_steps * training_warmup_steps_duration)\n",
        "\n",
        "print(\"Warmup steps:\", training_warmup_steps)"
      ],
      "id": "af6620a2",
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There will be approximately 5780 training steps.\n",
            "Warmup steps: 578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:18:02.469038Z",
          "iopub.status.busy": "2021-04-14T09:18:02.468393Z",
          "iopub.status.idle": "2021-04-14T09:18:02.623352Z",
          "shell.execute_reply": "2021-04-14T09:18:02.624314Z"
        },
        "id": "85799efc",
        "papermill": {
          "duration": 0.244883,
          "end_time": "2021-04-14T09:18:02.624583",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.379700",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    new_train_set, batch_size=training_batch_size,\n",
        "    shuffle=True, pin_memory=use_pin_memory)\n",
        "\n",
        "if validation_enabled:\n",
        "    validation_dataloader = torch.utils.data.DataLoader(\n",
        "        new_valid_set, batch_size=validation_batch_size, pin_memory=use_pin_memory)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = transformers.AdamW(\n",
        "    classifier.parameters(),\n",
        "    lr=training_learning_rate,\n",
        "    weight_decay=training_weight_decay)\n",
        "\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=training_warmup_steps,\n",
        "    num_training_steps=len(new_train_set) * training_epochs,\n",
        ")\n",
        "\n",
        "# The directory to save the best version of the head\n",
        "trained_model_directory = os.path.join('..', 'trained_models', experiment_id)\n",
        "\n",
        "shutil.rmtree(trained_model_directory, ignore_errors=True)\n",
        "os.makedirs(trained_model_directory)"
      ],
      "id": "85799efc",
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:18:02.806888Z",
          "iopub.status.busy": "2021-04-14T09:18:02.806235Z",
          "iopub.status.idle": "2021-04-14T09:18:02.809906Z",
          "shell.execute_reply": "2021-04-14T09:18:02.809300Z"
        },
        "id": "2164d6dc",
        "papermill": {
          "duration": 0.090842,
          "end_time": "2021-04-14T09:18:02.810040",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.719198",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def compute_metrics(predictions, labels):\n",
        "    preds = predictions.argmax(-1)\n",
        "\n",
        "    precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
        "        y_true=labels, y_pred=preds, labels=[0,1,2], average='macro')\n",
        "\n",
        "    acc = sklearn.metrics.accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "id": "2164d6dc",
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da810758",
        "papermill": {
          "duration": 0.078398,
          "end_time": "2021-04-14T09:18:02.966537",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.888139",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training loop"
      ],
      "id": "da810758"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32555d11",
        "papermill": {
          "duration": 0.106487,
          "end_time": "2021-04-14T10:25:54.578808",
          "exception": false,
          "start_time": "2021-04-14T10:25:54.472321",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Evaluation with in-domain test set"
      ],
      "id": "32555d11"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T10:25:54.738868Z",
          "iopub.status.busy": "2021-04-14T10:25:54.738386Z",
          "iopub.status.idle": "2021-04-14T10:25:54.741146Z",
          "shell.execute_reply": "2021-04-14T10:25:54.741526Z"
        },
        "id": "8442276c",
        "papermill": {
          "duration": 0.085244,
          "end_time": "2021-04-14T10:25:54.741640",
          "exception": false,
          "start_time": "2021-04-14T10:25:54.656396",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb077e0d-813f-4a30-e51c-120b1986daef"
      },
      "source": [
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=testing_batch_size, pin_memory=use_pin_memory)\n",
        "# Locate the weight file.\n",
        "trained_model_directory = os.path.join('NLIResults', experiment_id)\n",
        "\n",
        "saved_weights_name = ''\n",
        "\n",
        "for fname in os.listdir(trained_model_directory):\n",
        "    if fname.startswith('epoch'):\n",
        "        saved_weights_name = fname\n",
        "        break\n",
        "\n",
        "print(\"Loading\", saved_weights_name)"
      ],
      "id": "8442276c",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading epoch_18.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T10:25:54.910301Z",
          "iopub.status.busy": "2021-04-14T10:25:54.909777Z",
          "iopub.status.idle": "2021-04-14T10:26:30.883459Z",
          "shell.execute_reply": "2021-04-14T10:26:30.882519Z"
        },
        "papermill": {
          "duration": 36.067047,
          "end_time": "2021-04-14T10:26:30.883703",
          "exception": false,
          "start_time": "2021-04-14T10:25:54.816656",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "03fbf0400e5e46a696c9e53381f8b321",
            "3a93ecb5641c44108955da056720b345",
            "b0c9e05ebaab439e988b390d5d7ca570",
            "ac68c6d3f7aa4b00b4bbb9e16287b8f7",
            "cdeb1d59e2404baaa302bd8e52bb908e",
            "63cdb7539d1e40708f34387e340c3be5",
            "16090bf951a94040a08cdca6636c8142",
            "3fe604cc168d40eb90cc6ffc245c5474"
          ]
        },
        "id": "24ddd232",
        "outputId": "635e6144-f70d-4f4d-f7c4-735a0e5467c9"
      },
      "source": [
        "\n",
        "# Load the best found head weights\n",
        "with torch.no_grad():\n",
        "    \n",
        "    classifier_model.load_state_dict(torch.load(os.path.join(os.path.join('NLIResults', experiment_id), saved_weights_name),map_location=torch_device))\n",
        "\n",
        "    classifier.eval()\n",
        "\n",
        "    predictions_test = torch.Tensor().to(torch_device)\n",
        "\n",
        "    labels_test = torch.Tensor().to(torch_device)\n",
        "\n",
        "    for batch_test in tqdm.notebook.tqdm(test_dataloader):\n",
        "\n",
        "        reviews_repeated = []\n",
        "        prompts_populated = []\n",
        "\n",
        "        for i in range(len(batch_test[\"text\"])):\n",
        "            \n",
        "            for prompt in sentiment_prompts:\n",
        "                reviews_repeated.append(batch_test[\"text\"][i])\n",
        "                prompts_populated.append(prompt.format(aspect=\"things\"))\n",
        "\n",
        "        batch_encoded = tokenizer(\n",
        "            reviews_repeated, prompts_populated,\n",
        "            padding='max_length', truncation='only_first', max_length=256,\n",
        "            return_tensors='pt')\n",
        "        \n",
        "        batch_encoded.to(torch_device)\n",
        "\n",
        "        nli_output = nli_model(**batch_encoded)[\"logits\"]\n",
        "\n",
        "        labels = batch_test[\"sentiment\"]\n",
        "        labels = labels.to(torch_device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = classifier(batch_encoded)\n",
        "        \n",
        "        predictions_test = torch.cat([predictions_test, outputs])\n",
        "        labels_test = torch.cat([labels_test, labels])\n",
        "\n",
        "    # Compute metrics\n",
        "    test_metrics = compute_metrics(predictions_test.cpu(), labels_test.cpu())\n",
        "    \n",
        "    print(test_metrics)"
      ],
      "id": "24ddd232",
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03fbf0400e5e46a696c9e53381f8b321",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{'accuracy': 0.6394984326018809, 'f1': 0.5994030282303905, 'precision': 0.670296280609539, 'recall': 0.607234060397832}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ab3d621",
        "papermill": {
          "duration": 0.100598,
          "end_time": "2021-04-14T10:26:31.118456",
          "exception": false,
          "start_time": "2021-04-14T10:26:31.017858",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Results visualization"
      ],
      "id": "9ab3d621"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T10:26:31.331369Z",
          "iopub.status.busy": "2021-04-14T10:26:31.330655Z",
          "iopub.status.idle": "2021-04-14T10:26:31.693819Z",
          "shell.execute_reply": "2021-04-14T10:26:31.694913Z"
        },
        "id": "40353e9f",
        "papermill": {
          "duration": 0.476879,
          "end_time": "2021-04-14T10:26:31.695265",
          "exception": false,
          "start_time": "2021-04-14T10:26:31.218386",
          "status": "completed"
        },
        "tags": [],
        "outputId": "c173cf86-4f67-40bb-922b-7aa68fa4797f"
      },
      "source": [
        "# Calculate metrics and confusion matrix based upon predictions and true labels\n",
        "cm = sklearn.metrics.confusion_matrix(labels_test.cpu().detach().numpy(), predictions_test.cpu().detach().numpy().argmax(-1), labels=[0,1,2])\n",
        "\n",
        "df_cm = pd.DataFrame(\n",
        "    cm,\n",
        "    index=[i for i in [\"positive\", \"negative\", \"neutral\"]],\n",
        "    columns=[i for i in [\"positive\", \"negative\", \"neutral\"]])\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "ax = sn.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "\n",
        "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
        "plt.show()"
      ],
      "id": "40353e9f",
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.100383,
          "end_time": "2021-04-14T10:26:31.929814",
          "exception": false,
          "start_time": "2021-04-14T10:26:31.829431",
          "status": "completed"
        },
        "tags": [],
        "id": "192b42b7"
      },
      "source": [
        ""
      ],
      "id": "192b42b7",
      "execution_count": 147,
      "outputs": []
    }
  ]
}