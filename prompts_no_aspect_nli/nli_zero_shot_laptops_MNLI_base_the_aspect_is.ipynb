{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Tags",
    "colab": {
      "name": "nli_zero_shot_laptops_MNLI-base_the_aspect_is",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "nteract": {
      "version": "0.28.0"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4131.042453,
      "end_time": "2021-04-14T10:26:33.868071",
      "environment_variables": {},
      "exception": null,
      "input_path": "nli_experiment_template.ipynb",
      "output_path": "results_nli_supervised_in_domain_laptops/nli_supervised_in_domain_laptops_MNLI-base_I_felt_696.ipynb",
      "parameters": {
        "experiment_id": "nli_supervised_in_domain_laptops_MNLI-base_I_felt_696",
        "neg_prompt_indexes": [
          1
        ],
        "nli_model_path": "textattack/bert-base-uncased-MNLI",
        "pos_prompt_indexes": [
          0
        ],
        "random_seed": 696,
        "sentiment_prompts": [
          "I felt the {aspect} was good.",
          "I felt the {aspect} was bad."
        ],
        "testing_batch_size": 8,
        "testing_domain": "laptops",
        "training_batch_size": 8,
        "training_domain": "laptops"
      },
      "start_time": "2021-04-14T09:17:42.825618",
      "version": "2.3.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "86733ac880154bcd94e8a3edcb4109da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b6c2b22971334d4780cd607939343c29",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a74fe1d97a35481d988660bc8560d4aa",
              "IPY_MODEL_ae37d1d2f0e5495cbf2a88f29f18f557"
            ]
          }
        },
        "b6c2b22971334d4780cd607939343c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a74fe1d97a35481d988660bc8560d4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eae1639f778b40cf8ad1e2bd54c63bb8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 80,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 80,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffd357bf98664cdab69312406600cec0"
          }
        },
        "ae37d1d2f0e5495cbf2a88f29f18f557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e194123d1ae4bb8a976ec834b4265b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 80/80 [00:42&lt;00:00,  1.86it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59a1565c769c4f62840cb0d5cda13170"
          }
        },
        "eae1639f778b40cf8ad1e2bd54c63bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffd357bf98664cdab69312406600cec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e194123d1ae4bb8a976ec834b4265b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59a1565c769c4f62840cb0d5cda13170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYSFmGrp2wSp"
      },
      "source": [
        ""
      ],
      "id": "yYSFmGrp2wSp",
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvZa9Z3V2eGK"
      },
      "source": [
        ""
      ],
      "id": "NvZa9Z3V2eGK",
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2dd8e3a",
        "papermill": {
          "duration": 0.099569,
          "end_time": "2021-04-14T09:17:44.356246",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.256677",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Initial Setups"
      ],
      "id": "b2dd8e3a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09036ef8",
        "papermill": {
          "duration": 0.070817,
          "end_time": "2021-04-14T09:17:44.498175",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.427358",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## (Google Colab use only)"
      ],
      "id": "09036ef8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:44.656950Z",
          "iopub.status.busy": "2021-04-14T09:17:44.656291Z",
          "iopub.status.idle": "2021-04-14T09:17:44.660609Z",
          "shell.execute_reply": "2021-04-14T09:17:44.660079Z"
        },
        "id": "1e81b28a",
        "papermill": {
          "duration": 0.091994,
          "end_time": "2021-04-14T09:17:44.660753",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.568759",
          "status": "completed"
        },
        "tags": [],
        "outputId": "57659013-89de-46a5-a151-588edfca0d2d"
      },
      "source": [
        "# Use Google Colab\n",
        "use_colab = True\n",
        "\n",
        "# Is this notebook running on Colab?\n",
        "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
        "# should be available in this environment\n",
        "\n",
        "# Previous version used importlib, but we could do the same thing with\n",
        "# just attempting to import google.colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    colab_available = True\n",
        "except:\n",
        "    colab_available = False\n",
        "\n",
        "if use_colab and colab_available:\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # cd to the appropriate working directory under my Google Drive\n",
        "    %cd '/content/drive/My Drive/ATSC'\n",
        "    \n",
        "    # Install packages specified in requirements\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # List the directory contents\n",
        "    !ls"
      ],
      "id": "1e81b28a",
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/ATSC\n",
            "Requirement already satisfied: transformers==4.3.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (4.3.3)\n",
            "Requirement already satisfied: datasets==1.2.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.2.1)\n",
            "Requirement already satisfied: pytokenizations==0.7.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.7.2)\n",
            "Requirement already satisfied: spacy==2.3.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.3.5)\n",
            "Requirement already satisfied: en_core_web_sm from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.2.5)\n",
            "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.7.1)\n",
            "Requirement already satisfied: scikit-learn==0.24.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.24.1)\n",
            "Requirement already satisfied: seaborn==0.11.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.11.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (0.10.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (0.3.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (1.1.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (0.70.11.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (56.1.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (7.4.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (1.0.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->-r requirements.txt (line 6)) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 7)) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.11.1->-r requirements.txt (line 8)) (3.2.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.3.3->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3->-r requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1->-r requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1->-r requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn==0.11.1->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn==0.11.1->-r requirements.txt (line 8)) (0.10.0)\n",
            " apex-master.zip\n",
            " baseline\n",
            " bert_base_cache\n",
            " checkpoint-1210520\n",
            " checkpoint-553363.zip\n",
            " dataset_cache\n",
            "'dataset_cache (1)'\n",
            " dataset_files\n",
            " dataset_scripts\n",
            " GPT2\n",
            " gpt2_amazon\n",
            " gpt2_cache\n",
            " MLM\n",
            " NLI\n",
            " nli-checkpoint-epoch2\n",
            " nli_files.txt\n",
            " NLIResults\n",
            " prompt_lr_atsc_single_prompt_the_aspect_gpt-2_yelp_restaurants\n",
            " requirements.txt\n",
            " semeval_data_files\n",
            " smart_mlm_yelp_500k_15percent.ipynb\n",
            " utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b2be680",
        "papermill": {
          "duration": 0.071744,
          "end_time": "2021-04-14T09:17:44.804138",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.732394",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Experiment parameters"
      ],
      "id": "8b2be680"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIpbwIm11WT-"
      },
      "source": [
        "import torch\n",
        "class SinglePromptLogitSentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, lm, num_class, pseudo_label_words, target_token_id=-1):\n",
        "        super(SinglePromptLogitSentimentClassificationHead, self).__init__()\n",
        "\n",
        "        self.num_class = num_class\n",
        "        self.pseudo_label_words = pseudo_label_words\n",
        "        self.target_token_id = target_token_id\n",
        "\n",
        "        self.lm = lm\n",
        "        \n",
        "        # Is self.lm BERT or GPT-2?\n",
        "        if self.lm.config.architectures[0].startswith('Bert'):\n",
        "            # if self.lm is BERT, then mask_token_id should be specified\n",
        "            assert self.target_token_id != -1\n",
        "            self.lm_type = 'bert'\n",
        "        elif self.lm.config.architectures[0].startswith('GPT2'):\n",
        "            self.lm_type = 'gpt2'\n",
        "        else:\n",
        "            raise Exception('Unsupported language model type.')\n",
        "            \n",
        "        print(\"Detected LM type:\", self.lm_type)\n",
        "\n",
        "    def forward(self, reviews_and_prompts):\n",
        "\n",
        "        if self.lm_type == 'bert':\n",
        "            # Figures out where the mask token was placed\n",
        "            target_indexes = (reviews_and_prompts.data[\"input_ids\"] == self.target_token_id)\n",
        "\n",
        "            lm_outputs = self.lm(**reviews_and_prompts)\n",
        "\n",
        "            outputs = lm_outputs.logits[target_indexes]\n",
        "        \n",
        "            outputs = outputs[:, self.pseudo_label_words]\n",
        "            \n",
        "        elif self.lm_type == 'gpt2':\n",
        "            \n",
        "            outputs = []\n",
        "            \n",
        "            for example in reviews_and_prompts:\n",
        "                lm_outputs = self.lm(**example, return_dict=True)\n",
        "                \n",
        "                lm_predictions = lm_outputs.logits[0, len(example['input_ids'][0]) - 1, self.pseudo_label_words]\n",
        "                \n",
        "                outputs.append(lm_predictions)\n",
        "\n",
        "            outputs = torch.stack(outputs, dim=0)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class MultiPromptSentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, lm, num_class, num_prompts, target_token_id=-1):\n",
        "        super(MultiPromptSentimentClassificationHead, self).__init__()\n",
        "\n",
        "        self.num_class = num_class\n",
        "        self.num_prompts = num_prompts\n",
        "        self.target_token_id = target_token_id\n",
        "\n",
        "        self.lm = lm\n",
        "        \n",
        "        # Is self.lm BERT or GPT-2?\n",
        "        if self.lm.config.architectures[0].startswith('Bert'):\n",
        "            # if self.lm is BERT, then mask_token_id should be specified\n",
        "            assert self.target_token_id != -1\n",
        "            self.lm_type = 'bert'\n",
        "        elif self.lm.config.architectures[0].startswith('GPT2'):\n",
        "            self.lm_type = 'gpt2'\n",
        "        else:\n",
        "            raise Exception('Unsupported language model type.')\n",
        "\n",
        "        print(\"Detected LM type:\", self.lm_type)\n",
        "\n",
        "        # Linear layer\n",
        "        self.linear = torch.nn.Linear(\n",
        "            self.num_prompts * self.lm.config.hidden_size, self.num_class)\n",
        "\n",
        "    def forward(self, reviews_and_prompts):\n",
        "\n",
        "        # Extract hidden states and feed them to self.linear\n",
        "        outputs = []\n",
        "\n",
        "        lr_inputs_batch = []\n",
        "\n",
        "        # Figures out where the mask token was placed\n",
        "        if self.lm_type == 'bert':\n",
        "            # For BERT, we need to find the token in each input with [MASK]\n",
        "            target_indexes = torch.nonzero(\n",
        "                reviews_and_prompts.data[\"input_ids\"] == self.target_token_id)[:, 1]\n",
        "\n",
        "            lm_outputs = self.lm(**reviews_and_prompts, output_hidden_states=True)\n",
        "\n",
        "            real_batch_size = len(reviews_and_prompts.data[\"input_ids\"]) // self.num_prompts\n",
        "\n",
        "        elif self.lm_type == 'gpt2':\n",
        "            lm_outputs = []\n",
        "            target_indexes = []\n",
        "\n",
        "            # For GPT-2, we need to find the spot right after the input text\n",
        "            for example in reviews_and_prompts:\n",
        "                target_indexes.append(len(example['input_ids'][0]) - 1)\n",
        "\n",
        "                lm_outputs.append(self.lm(**example, output_hidden_states=True))\n",
        "\n",
        "            real_batch_size = len(reviews_and_prompts) // self.num_prompts\n",
        "                \n",
        "        for i in range(real_batch_size):\n",
        "            # Create an input to self.linear by\n",
        "            # concatenating last hidden states for this review\n",
        "            lr_input = []\n",
        "\n",
        "            for j in range(self.num_prompts):\n",
        "                if self.lm_type == 'bert':\n",
        "                    lr_input.append(lm_outputs[\"hidden_states\"][-1][i+real_batch_size*j][target_indexes[i+real_batch_size*j]])\n",
        "                elif self.lm_type == 'gpt2':\n",
        "                    lr_input.append(lm_outputs[i+real_batch_size*j][\"hidden_states\"][-1][0][target_indexes[i+real_batch_size*j]])\n",
        "                    \n",
        "            lr_input = torch.cat(lr_input, dim=0)\n",
        "\n",
        "            lr_inputs_batch.append(lr_input)\n",
        "\n",
        "        lr_inputs_batch = torch.stack(lr_inputs_batch)\n",
        "\n",
        "        outputs = self.linear(lr_inputs_batch)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class NoPromptSentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, lm, num_class):\n",
        "        super(NoPromptSentimentClassificationHead, self).__init__()\n",
        "\n",
        "        self.num_class = num_class\n",
        "\n",
        "        self.lm = lm\n",
        "\n",
        "        self.linear = torch.nn.Linear(\n",
        "            self.lm.config.hidden_size, self.num_class)\n",
        "\n",
        "    def forward(self, reviews_and_prompts):\n",
        "\n",
        "        lm_outputs = self.lm(**reviews_and_prompts, output_hidden_states=True)\n",
        "\n",
        "        # Last hidden state for [CLS] token\n",
        "        last_hidden_state_cls = lm_outputs[\"hidden_states\"][-1][:, 0, :]\n",
        "        \n",
        "        outputs = self.linear(last_hidden_state_cls)\n",
        "\n",
        "        return outputs\n",
        "    \n",
        "class NLISentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, nli_model, num_prompts, pos_prompt_indexes, neg_prompt_indexes):\n",
        "        super(NLISentimentClassificationHead, self).__init__()\n",
        "        \n",
        "        self.num_prompts = num_prompts\n",
        "        self.nli_model = nli_model\n",
        "        \n",
        "        self.pos_prompt_indexes = pos_prompt_indexes\n",
        "        self.neg_prompt_indexes = neg_prompt_indexes\n",
        "        \n",
        "    def forward(self, reviews_and_prompts):\n",
        "        \n",
        "        nli_output = self.nli_model(**reviews_and_prompts)[\"logits\"]\n",
        "\n",
        "        outputs = torch.Tensor().to(self.nli_model.device)\n",
        "\n",
        "        # Text Attack NLI Labels: 0-> Contradiction, 1-> Entailment, 2-> Neutral\n",
        "        # Sentiment Polarity Labels: 0-> Positive, 1-> Negative, 2-> Neutral\n",
        "        for i in range(len(nli_output)//self.num_prompts):\n",
        "            prompts_batch = nli_output[i*self.num_prompts:(i+1)*self.num_prompts]\n",
        "\n",
        "            pos_logit = torch.mean(prompts_batch[self.pos_prompt_indexes], dim=0)[1]\n",
        "\n",
        "            neg_logit = torch.mean(prompts_batch[self.neg_prompt_indexes], dim=0)[1]\n",
        "\n",
        "            neu_logit = torch.mean(prompts_batch, dim=0)[2]\n",
        "\n",
        "            pred_logits = torch.stack([pos_logit, neg_logit, neu_logit])\n",
        "            pred_logits = torch.reshape(pred_logits, (1,-1))\n",
        "\n",
        "            outputs = torch.cat([outputs, pred_logits])\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class NLIMinSentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, nli_model, num_prompts, pos_prompt_indexes, neg_prompt_indexes):\n",
        "        super(NLIMinSentimentClassificationHead, self).__init__()\n",
        "        \n",
        "        self.num_prompts = num_prompts\n",
        "        self.nli_model = nli_model\n",
        "        \n",
        "        self.pos_prompt_indexes = pos_prompt_indexes\n",
        "        self.neg_prompt_indexes = neg_prompt_indexes\n",
        "        \n",
        "    def forward(self, reviews_and_prompts):\n",
        "        \n",
        "        nli_output = self.nli_model(**reviews_and_prompts)[\"logits\"]\n",
        "\n",
        "        outputs = torch.Tensor().to(self.nli_model.device)\n",
        "\n",
        "        # Text Attack NLI Labels: 0-> Contradiction, 1-> Entailment, 2-> Neutral\n",
        "        # Sentiment Polarity Labels: 0-> Positive, 1-> Negative, 2-> Neutral\n",
        "        for i in range(len(nli_output)//self.num_prompts):\n",
        "            prompts_batch = nli_output[i*self.num_prompts:(i+1)*self.num_prompts]\n",
        "\n",
        "            pos_logit = torch.mean(prompts_batch[self.pos_prompt_indexes], dim=0)[1]\n",
        "\n",
        "            neg_logit = torch.mean(prompts_batch[self.neg_prompt_indexes], dim=0)[1]\n",
        "\n",
        "            neu_logit = torch.min(prompts_batch, dim=0)[0][2]\n",
        "\n",
        "            pred_logits = torch.stack([pos_logit, neg_logit, neu_logit])\n",
        "            pred_logits = torch.reshape(pred_logits, (1,-1))\n",
        "\n",
        "            outputs = torch.cat([outputs, pred_logits])\n",
        "\n",
        "        return outputs\n"
      ],
      "id": "DIpbwIm11WT-",
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:44.957547Z",
          "iopub.status.busy": "2021-04-14T09:17:44.956864Z",
          "iopub.status.idle": "2021-04-14T09:17:44.960465Z",
          "shell.execute_reply": "2021-04-14T09:17:44.959837Z"
        },
        "id": "205c591d",
        "papermill": {
          "duration": 0.084988,
          "end_time": "2021-04-14T09:17:44.960595",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.875607",
          "status": "completed"
        },
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "\n",
        "# We will use the following string ID to identify this particular (training) experiments\n",
        "# in directory paths and other settings\n",
        "experiment_id = 'supervised_nli_single_prompt_1_in_domain_restaurant_MNLI_base_seed_696'\n",
        "\n",
        "# Random seed\n",
        "random_seed = 696\n",
        "\n",
        "# path to pretrained nli model folder or the string \"textattack/bert-base-uncased-MNLI\"\n",
        "nli_model_path = \"textattack/bert-base-uncased-MNLI\"\n",
        "\n",
        "# Prompts to be added to the end of each review text\n",
        "sentiment_prompts = [\n",
        "    \"The {aspect} is good.\",\n",
        "    \"The {aspect} is bad.\"]\n",
        "\n",
        "#index of the prompts in the sentiment_prompts by polarity for later grouping\n",
        "pos_prompt_indexes = [0]\n",
        "neg_prompt_indexes = [1]\n",
        "\n",
        "#What datasets to be used for training and testing loops\n",
        "training_domain = \"restaurants\"\n",
        "testing_domain = \"restaurants\"\n",
        "\n",
        "# Training settings\n",
        "training_epochs = 20\n",
        "training_batch_size = 8\n",
        "training_learning_rate = 2e-5\n",
        "training_weight_decay = 0.01\n",
        "training_warmup_steps_duration = 0.1\n",
        "training_best_model_criterion = 'train_loss'\n",
        "\n",
        "training_lm_freeze = False\n",
        "\n",
        "validation_enabled = False\n",
        "validation_dataset_proportion = 0.2\n",
        "validation_batch_size = 8\n",
        "\n",
        "testing_batch_size = 32"
      ],
      "id": "205c591d",
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:45.125761Z",
          "iopub.status.busy": "2021-04-14T09:17:45.125025Z",
          "iopub.status.idle": "2021-04-14T09:17:45.128050Z",
          "shell.execute_reply": "2021-04-14T09:17:45.127424Z"
        },
        "papermill": {
          "duration": 0.08669,
          "end_time": "2021-04-14T09:17:45.128255",
          "exception": false,
          "start_time": "2021-04-14T09:17:45.041565",
          "status": "completed"
        },
        "tags": [
          "injected-parameters"
        ],
        "id": "33158748"
      },
      "source": [
        "# Parameters\n",
        "experiment_id = \"nli_zero_shot_laptops_MNLI-base_the_aspect_is\"\n",
        "random_seed = 696\n",
        "nli_model_path = \"textattack/bert-base-uncased-MNLI\"\n",
        "sentiment_prompts = [\"The {aspect} are good.\", \"The {aspect} are bad.\"]\n",
        "pos_prompt_indexes = [0]\n",
        "neg_prompt_indexes = [1]\n",
        "training_domain = \"laptops\"\n",
        "testing_batch_size = 8\n",
        "testing_domain = \"laptops\"\n",
        "training_batch_size = 8\n"
      ],
      "id": "33158748",
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "169e034b",
        "papermill": {
          "duration": 0.059185,
          "end_time": "2021-04-14T09:17:45.258934",
          "exception": false,
          "start_time": "2021-04-14T09:17:45.199749",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Package imports"
      ],
      "id": "169e034b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:45.381681Z",
          "iopub.status.busy": "2021-04-14T09:17:45.381034Z",
          "iopub.status.idle": "2021-04-14T09:17:48.668262Z",
          "shell.execute_reply": "2021-04-14T09:17:48.669304Z"
        },
        "id": "18d534de",
        "papermill": {
          "duration": 3.355855,
          "end_time": "2021-04-14T09:17:48.669607",
          "exception": false,
          "start_time": "2021-04-14T09:17:45.313752",
          "status": "completed"
        },
        "tags": [],
        "outputId": "28506414-e853-4218-e518-9466f76226f0"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import copy\n",
        "import inspect\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "import datasets\n",
        "import sklearn.metrics\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import tqdm\n",
        "\n",
        "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
        "parent_dir = os.path.dirname(current_dir)\n",
        "sys.path.append(parent_dir)\n",
        "\n",
        "import utils\n",
        "\n",
        "# Random seed settings\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "# cuBLAS reproducibility\n",
        "# https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
        "torch.set_deterministic(True)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# Print version information\n",
        "print(\"Python version: \" + sys.version)\n",
        "print(\"NumPy version: \" + np.__version__)\n",
        "print(\"PyTorch version: \" + torch.__version__)\n",
        "print(\"Transformers version: \" + transformers.__version__)"
      ],
      "id": "18d534de",
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version: 3.7.10 (default, May  3 2021, 02:48:31) \n",
            "[GCC 7.5.0]\n",
            "NumPy version: 1.19.5\n",
            "PyTorch version: 1.7.1\n",
            "Transformers version: 4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78f1ee52",
        "papermill": {
          "duration": 0.067281,
          "end_time": "2021-04-14T09:17:48.839940",
          "exception": false,
          "start_time": "2021-04-14T09:17:48.772659",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## PyTorch GPU settings"
      ],
      "id": "78f1ee52"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:50.767583Z",
          "iopub.status.busy": "2021-04-14T09:17:49.016404Z",
          "iopub.status.idle": "2021-04-14T09:17:50.771850Z",
          "shell.execute_reply": "2021-04-14T09:17:50.772413Z"
        },
        "id": "53d9ba9a",
        "papermill": {
          "duration": 1.862641,
          "end_time": "2021-04-14T09:17:50.772589",
          "exception": false,
          "start_time": "2021-04-14T09:17:48.909948",
          "status": "completed"
        },
        "tags": [],
        "outputId": "0ff19974-c294-46d3-a3db-cafd083f05a6"
      },
      "source": [
        "\n",
        "if torch.cuda.is_available():    \n",
        "    torch_device = torch.device('cuda')\n",
        "\n",
        "    # Set this to True to make your output immediately reproducible\n",
        "    # Note: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "    # Disable 'benchmark' mode: Set this False if you want to measure running times more fairly\n",
        "    # Note: https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    \n",
        "    # Faster Host to GPU copies with page-locked memory\n",
        "    use_pin_memory = True\n",
        "    \n",
        "    # Number of compute devices to be used for training\n",
        "    training_device_count = torch.cuda.device_count()\n",
        "\n",
        "    # CUDA libraries version information\n",
        "    print(\"CUDA Version: \" + str(torch.version.cuda))\n",
        "    print(\"cuDNN Version: \" + str(torch.backends.cudnn.version()))\n",
        "    print(\"CUDA Device Name: \" + str(torch.cuda.get_device_name()))\n",
        "    print(\"CUDA Capabilities: \"+ str(torch.cuda.get_device_capability()))\n",
        "    print(\"Number of CUDA devices: \"+ str(training_device_count))\n",
        "    \n",
        "else:\n",
        "    torch_device = torch.device('cpu')\n",
        "    use_pin_memory = False\n",
        "    \n",
        "    # Number of compute devices to be used for training\n",
        "    training_device_count = 1\n",
        "\n",
        "print()\n",
        "print(\"PyTorch device selected:\", torch_device)"
      ],
      "id": "53d9ba9a",
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Version: 10.2\n",
            "cuDNN Version: 7605\n",
            "CUDA Device Name: Tesla T4\n",
            "CUDA Capabilities: (7, 5)\n",
            "Number of CUDA devices: 1\n",
            "\n",
            "PyTorch device selected: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30f1f1cb",
        "papermill": {
          "duration": 0.072829,
          "end_time": "2021-04-14T09:17:50.920232",
          "exception": false,
          "start_time": "2021-04-14T09:17:50.847403",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Prepare Datasets for Prompt-based Classifier"
      ],
      "id": "30f1f1cb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b25dbc88",
        "papermill": {
          "duration": 0.072759,
          "end_time": "2021-04-14T09:17:51.066279",
          "exception": false,
          "start_time": "2021-04-14T09:17:50.993520",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Load the SemEval dataset"
      ],
      "id": "b25dbc88"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:51.227509Z",
          "iopub.status.busy": "2021-04-14T09:17:51.226811Z",
          "iopub.status.idle": "2021-04-14T09:17:51.948638Z",
          "shell.execute_reply": "2021-04-14T09:17:51.947637Z"
        },
        "id": "a4e71c29",
        "papermill": {
          "duration": 0.805682,
          "end_time": "2021-04-14T09:17:51.948940",
          "exception": false,
          "start_time": "2021-04-14T09:17:51.143258",
          "status": "completed"
        },
        "tags": [],
        "outputId": "ad50088f-f0a2-46fd-fbf8-01b22f42ec0a"
      },
      "source": [
        "# Load semeval for both domains\n",
        "laptop_semeval_dataset = datasets.load_dataset(\n",
        "    os.path.abspath('./dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
        "    data_files={\n",
        "        'test': './dataset_files/semeval_2014/Laptops_Test_Gold.xml',\n",
        "        'train': './dataset_files/semeval_2014/Laptop_Train_v2.xml',\n",
        "    },\n",
        "    cache_dir='./dataset_cache')\n",
        "\n",
        "restaurant_semeval_dataset = datasets.load_dataset(\n",
        "    os.path.abspath('./dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
        "    data_files={\n",
        "        'test': './dataset_files/semeval_2014/Restaurants_Test_Gold.xml',\n",
        "        'train': './dataset_files/semeval_2014/Restaurants_Train_v2.xml',\n",
        "    },\n",
        "    cache_dir='./dataset_cache')"
      ],
      "id": "a4e71c29",
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset sem_eval2014_task4_dataset (./dataset_cache/sem_eval2014_task4_dataset/default-2ba098669778f075/0.0.1/f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969)\n",
            "Using custom data configuration default\n",
            "Reusing dataset sem_eval2014_task4_dataset (./dataset_cache/sem_eval2014_task4_dataset/default-00707989ebea381d/0.0.1/f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.127349Z",
          "iopub.status.busy": "2021-04-14T09:17:52.126410Z",
          "iopub.status.idle": "2021-04-14T09:17:52.128934Z",
          "shell.execute_reply": "2021-04-14T09:17:52.129482Z"
        },
        "id": "234dcdac",
        "papermill": {
          "duration": 0.081917,
          "end_time": "2021-04-14T09:17:52.129628",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.047711",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "dataset_dic_train = {\n",
        "    \"laptops\": laptop_semeval_dataset['train'],\n",
        "    \"restaurants\": restaurant_semeval_dataset['train']\n",
        "}\n",
        "\n",
        "dataset_dic_test = {\n",
        "    \"laptops\": laptop_semeval_dataset['test'],\n",
        "    \"restaurants\": restaurant_semeval_dataset['test']\n",
        "}\n"
      ],
      "id": "234dcdac",
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.284055Z",
          "iopub.status.busy": "2021-04-14T09:17:52.283164Z",
          "iopub.status.idle": "2021-04-14T09:17:52.285775Z",
          "shell.execute_reply": "2021-04-14T09:17:52.286325Z"
        },
        "papermill": {
          "duration": 0.081159,
          "end_time": "2021-04-14T09:17:52.286474",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.205315",
          "status": "completed"
        },
        "tags": [],
        "id": "3b556c52"
      },
      "source": [
        "# The dataset chosen for training and testing\n",
        "train_set = dataset_dic_train[training_domain]\n",
        "test_set = dataset_dic_test[testing_domain]"
      ],
      "id": "3b556c52",
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42aeac01",
        "papermill": {
          "duration": 0.074267,
          "end_time": "2021-04-14T09:17:52.434905",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.360638",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Train-validation split"
      ],
      "id": "42aeac01"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.589122Z",
          "iopub.status.busy": "2021-04-14T09:17:52.588365Z",
          "iopub.status.idle": "2021-04-14T09:17:52.592239Z",
          "shell.execute_reply": "2021-04-14T09:17:52.591606Z"
        },
        "id": "c5201e50",
        "papermill": {
          "duration": 0.082863,
          "end_time": "2021-04-14T09:17:52.592369",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.509506",
          "status": "completed"
        },
        "tags": [],
        "outputId": "ea71fcf5-8d52-405a-b219-2a38dbaf6b66"
      },
      "source": [
        "# Training set size after validation split\n",
        "if validation_enabled:\n",
        "    new_train_dataset_size = int(len(train_set) * (1 - validation_dataset_proportion))\n",
        "    new_valid_dataset_size = len(train_set) - new_train_dataset_size\n",
        "    print(\"Training dataset after split:\", new_train_dataset_size)\n",
        "    print(\"Validation dataset after split:\", new_train_dataset_size)\n",
        "else:\n",
        "    new_train_dataset_size = len(train_set)\n",
        "    print(\"Training dataset size:\", new_train_dataset_size)"
      ],
      "id": "c5201e50",
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset size: 2313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.730472Z",
          "iopub.status.busy": "2021-04-14T09:17:52.729971Z",
          "iopub.status.idle": "2021-04-14T09:17:52.787818Z",
          "shell.execute_reply": "2021-04-14T09:17:52.787292Z"
        },
        "id": "8710a9bd",
        "papermill": {
          "duration": 0.120927,
          "end_time": "2021-04-14T09:17:52.787955",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.667028",
          "status": "completed"
        },
        "tags": [],
        "outputId": "7fb54f2e-6bac-4a5e-e5d9-92f433fed1aa"
      },
      "source": [
        "train_set = train_set.shuffle(seed=random_seed)\n",
        "\n",
        "new_train_set = train_set.select(indices=np.arange(new_train_dataset_size))\n",
        "\n",
        "if validation_enabled:\n",
        "    new_valid_set = train_set.select(\n",
        "        indices=np.arange(\n",
        "            new_train_dataset_size,\n",
        "            new_train_dataset_size + new_valid_dataset_size))"
      ],
      "id": "8710a9bd",
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached shuffled indices for dataset at ./dataset_cache/sem_eval2014_task4_dataset/default-2ba098669778f075/0.0.1/f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969/cache-de8ce8ac91817d47.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.913145Z",
          "iopub.status.busy": "2021-04-14T09:17:52.912611Z",
          "iopub.status.idle": "2021-04-14T09:17:52.915730Z",
          "shell.execute_reply": "2021-04-14T09:17:52.915257Z"
        },
        "id": "60a082f3",
        "papermill": {
          "duration": 0.06474,
          "end_time": "2021-04-14T09:17:52.915829",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.851089",
          "status": "completed"
        },
        "tags": [],
        "outputId": "b8b8a33d-9168-4557-dba5-715720ce2948"
      },
      "source": [
        "print(new_train_set[0])"
      ],
      "id": "60a082f3",
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'aspect': 'loads', 'sentiment': 2, 'text': 'Once I removed all the software the laptop loads in 15-20 seconds.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1865dbeb",
        "papermill": {
          "duration": 0.059399,
          "end_time": "2021-04-14T09:17:53.035203",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.975804",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Supervised ATSC with Prompts + Logistic Regression Head"
      ],
      "id": "1865dbeb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08dca259",
        "papermill": {
          "duration": 0.057453,
          "end_time": "2021-04-14T09:17:53.150677",
          "exception": false,
          "start_time": "2021-04-14T09:17:53.093224",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Load the pretrained LM"
      ],
      "id": "08dca259"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:53.270315Z",
          "iopub.status.busy": "2021-04-14T09:17:53.269643Z",
          "iopub.status.idle": "2021-04-14T09:17:58.431562Z",
          "shell.execute_reply": "2021-04-14T09:17:58.432583Z"
        },
        "id": "56a24d11",
        "papermill": {
          "duration": 5.224628,
          "end_time": "2021-04-14T09:17:58.432932",
          "exception": false,
          "start_time": "2021-04-14T09:17:53.208304",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Load pretrained language model\n",
        "nli_model = transformers.AutoModelForSequenceClassification.from_pretrained(nli_model_path)\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-MNLI\", cache_dir='../bert_base_cache')"
      ],
      "id": "56a24d11",
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:58.618927Z",
          "iopub.status.busy": "2021-04-14T09:17:58.618342Z",
          "iopub.status.idle": "2021-04-14T09:17:58.621535Z",
          "shell.execute_reply": "2021-04-14T09:17:58.621050Z"
        },
        "papermill": {
          "duration": 0.079367,
          "end_time": "2021-04-14T09:17:58.621647",
          "exception": false,
          "start_time": "2021-04-14T09:17:58.542280",
          "status": "completed"
        },
        "tags": [],
        "id": "3e1bfc3f"
      },
      "source": [
        "# Freeze all layers in lm.\n",
        "if training_lm_freeze:\n",
        "    for param in nli_model.parameters():\n",
        "        param.requires_grad = False"
      ],
      "id": "3e1bfc3f",
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:58.748044Z",
          "iopub.status.busy": "2021-04-14T09:17:58.747553Z",
          "iopub.status.idle": "2021-04-14T09:18:01.944791Z",
          "shell.execute_reply": "2021-04-14T09:18:01.945802Z"
        },
        "papermill": {
          "duration": 3.262784,
          "end_time": "2021-04-14T09:18:01.946086",
          "exception": false,
          "start_time": "2021-04-14T09:17:58.683302",
          "status": "completed"
        },
        "tags": [],
        "id": "c5220e7a"
      },
      "source": [
        "classifier = NLISentimentClassificationHead(\n",
        "                    nli_model = nli_model,\n",
        "                    num_prompts = len(sentiment_prompts),\n",
        "                    pos_prompt_indexes = pos_prompt_indexes,\n",
        "                    neg_prompt_indexes = neg_prompt_indexes\n",
        "                    )\n",
        "classifier_model = classifier.to(torch_device)"
      ],
      "id": "c5220e7a",
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72da7aad",
        "papermill": {
          "duration": 0.078495,
          "end_time": "2021-04-14T09:18:02.134812",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.056317",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training settings"
      ],
      "id": "72da7aad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:18:02.297951Z",
          "iopub.status.busy": "2021-04-14T09:18:02.297293Z",
          "iopub.status.idle": "2021-04-14T09:18:02.301372Z",
          "shell.execute_reply": "2021-04-14T09:18:02.301889Z"
        },
        "papermill": {
          "duration": 0.090522,
          "end_time": "2021-04-14T09:18:02.302042",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.211520",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af6620a2",
        "outputId": "8ee874d2-6cec-4e62-fdd1-0e509e4b5c67"
      },
      "source": [
        "# How many training steps would we have?\n",
        "approx_total_training_steps = len(new_train_set) // training_batch_size * training_epochs\n",
        "\n",
        "print(\"There will be approximately %d training steps.\" % approx_total_training_steps)\n",
        "\n",
        "# Let's have warmups for the first (training_warmup_steps_duration)% of steps.\n",
        "training_warmup_steps = int(approx_total_training_steps * training_warmup_steps_duration)\n",
        "\n",
        "print(\"Warmup steps:\", training_warmup_steps)"
      ],
      "id": "af6620a2",
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There will be approximately 5780 training steps.\n",
            "Warmup steps: 578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:18:02.469038Z",
          "iopub.status.busy": "2021-04-14T09:18:02.468393Z",
          "iopub.status.idle": "2021-04-14T09:18:02.623352Z",
          "shell.execute_reply": "2021-04-14T09:18:02.624314Z"
        },
        "id": "85799efc",
        "papermill": {
          "duration": 0.244883,
          "end_time": "2021-04-14T09:18:02.624583",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.379700",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    new_train_set, batch_size=training_batch_size,\n",
        "    shuffle=True, pin_memory=use_pin_memory)\n",
        "\n",
        "if validation_enabled:\n",
        "    validation_dataloader = torch.utils.data.DataLoader(\n",
        "        new_valid_set, batch_size=validation_batch_size, pin_memory=use_pin_memory)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = transformers.AdamW(\n",
        "    classifier.parameters(),\n",
        "    lr=training_learning_rate,\n",
        "    weight_decay=training_weight_decay)\n",
        "\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=training_warmup_steps,\n",
        "    num_training_steps=len(new_train_set) * training_epochs,\n",
        ")\n",
        "\n",
        "# The directory to save the best version of the head\n",
        "trained_model_directory = os.path.join('..', 'trained_models', experiment_id)\n",
        "\n",
        "shutil.rmtree(trained_model_directory, ignore_errors=True)\n",
        "os.makedirs(trained_model_directory)"
      ],
      "id": "85799efc",
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:18:02.806888Z",
          "iopub.status.busy": "2021-04-14T09:18:02.806235Z",
          "iopub.status.idle": "2021-04-14T09:18:02.809906Z",
          "shell.execute_reply": "2021-04-14T09:18:02.809300Z"
        },
        "id": "2164d6dc",
        "papermill": {
          "duration": 0.090842,
          "end_time": "2021-04-14T09:18:02.810040",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.719198",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def compute_metrics(predictions, labels):\n",
        "    preds = predictions.argmax(-1)\n",
        "\n",
        "    precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
        "        y_true=labels, y_pred=preds, labels=[0,1,2], average='macro')\n",
        "\n",
        "    acc = sklearn.metrics.accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "id": "2164d6dc",
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da810758",
        "papermill": {
          "duration": 0.078398,
          "end_time": "2021-04-14T09:18:02.966537",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.888139",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training loop"
      ],
      "id": "da810758"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32555d11",
        "papermill": {
          "duration": 0.106487,
          "end_time": "2021-04-14T10:25:54.578808",
          "exception": false,
          "start_time": "2021-04-14T10:25:54.472321",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Evaluation with in-domain test set"
      ],
      "id": "32555d11"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "86733ac880154bcd94e8a3edcb4109da",
            "b6c2b22971334d4780cd607939343c29",
            "a74fe1d97a35481d988660bc8560d4aa",
            "ae37d1d2f0e5495cbf2a88f29f18f557",
            "eae1639f778b40cf8ad1e2bd54c63bb8",
            "ffd357bf98664cdab69312406600cec0",
            "7e194123d1ae4bb8a976ec834b4265b6",
            "59a1565c769c4f62840cb0d5cda13170"
          ]
        },
        "id": "_SRDl9IzgHXY",
        "outputId": "61a9565e-4e0f-406a-d19a-8c1512f00a30"
      },
      "source": [
        "\n",
        "# Load the best found head weights\n",
        "with torch.no_grad():\n",
        "\n",
        "    classifier.eval()\n",
        "\n",
        "    predictions_test = torch.Tensor().to(torch_device)\n",
        "\n",
        "    labels_test = torch.Tensor().to(torch_device)\n",
        "\n",
        "    for batch_test in tqdm.notebook.tqdm(test_dataloader):\n",
        "\n",
        "        reviews_repeated = []\n",
        "        prompts_populated = []\n",
        "\n",
        "        for i in range(len(batch_test[\"text\"])):\n",
        "            \n",
        "            for prompt in sentiment_prompts:\n",
        "                reviews_repeated.append(batch_test[\"text\"][i])\n",
        "                prompts_populated.append(prompt.format(aspect=batch_test[\"aspect\"][i]))\n",
        "\n",
        "        batch_encoded = tokenizer(\n",
        "            reviews_repeated, prompts_populated,\n",
        "            padding='max_length', truncation='only_first', max_length=256,\n",
        "            return_tensors='pt')\n",
        "        \n",
        "        batch_encoded.to(torch_device)\n",
        "\n",
        "        nli_output = nli_model(**batch_encoded)[\"logits\"]\n",
        "\n",
        "        labels = batch_test[\"sentiment\"]\n",
        "        labels = labels.to(torch_device)\n",
        "        \n",
        "        outputs = classifier(batch_encoded)\n",
        "        \n",
        "        predictions_test = torch.cat([predictions_test, outputs])\n",
        "        labels_test = torch.cat([labels_test, labels])\n",
        "\n",
        "    # Compute metrics\n",
        "    test_metrics = compute_metrics(predictions_test.cpu(), labels_test.cpu())\n",
        "    \n",
        "    print(test_metrics)"
      ],
      "id": "_SRDl9IzgHXY",
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86733ac880154bcd94e8a3edcb4109da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{'accuracy': 0.664576802507837, 'f1': 0.6174589642335635, 'precision': 0.7569379620424267, 'recall': 0.6290323484414676}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ab3d621",
        "papermill": {
          "duration": 0.100598,
          "end_time": "2021-04-14T10:26:31.118456",
          "exception": false,
          "start_time": "2021-04-14T10:26:31.017858",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Results visualization"
      ],
      "id": "9ab3d621"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T10:26:31.331369Z",
          "iopub.status.busy": "2021-04-14T10:26:31.330655Z",
          "iopub.status.idle": "2021-04-14T10:26:31.693819Z",
          "shell.execute_reply": "2021-04-14T10:26:31.694913Z"
        },
        "id": "40353e9f",
        "papermill": {
          "duration": 0.476879,
          "end_time": "2021-04-14T10:26:31.695265",
          "exception": false,
          "start_time": "2021-04-14T10:26:31.218386",
          "status": "completed"
        },
        "tags": [],
        "outputId": "af815d6b-e9ff-4c70-eee2-7a39ccbd7b68"
      },
      "source": [
        "# Calculate metrics and confusion matrix based upon predictions and true labels\n",
        "cm = sklearn.metrics.confusion_matrix(labels_test.cpu().detach().numpy(), predictions_test.cpu().detach().numpy().argmax(-1), labels=[0,1,2])\n",
        "\n",
        "df_cm = pd.DataFrame(\n",
        "    cm,\n",
        "    index=[i for i in [\"positive\", \"negative\", \"neutral\"]],\n",
        "    columns=[i for i in [\"positive\", \"negative\", \"neutral\"]])\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "ax = sn.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "\n",
        "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
        "plt.show()"
      ],
      "id": "40353e9f",
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.100383,
          "end_time": "2021-04-14T10:26:31.929814",
          "exception": false,
          "start_time": "2021-04-14T10:26:31.829431",
          "status": "completed"
        },
        "tags": [],
        "id": "192b42b7"
      },
      "source": [
        ""
      ],
      "id": "192b42b7",
      "execution_count": null,
      "outputs": []
    }
  ]
}