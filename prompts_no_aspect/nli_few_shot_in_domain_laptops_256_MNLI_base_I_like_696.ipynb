{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Tags",
    "colab": {
      "name": "nli_few_shot_in_domain_laptops_256_MNLI-base_I_like_696",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "nteract": {
      "version": "0.28.0"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4131.042453,
      "end_time": "2021-04-14T10:26:33.868071",
      "environment_variables": {},
      "exception": null,
      "input_path": "nli_experiment_template.ipynb",
      "output_path": "results_nli_supervised_in_domain_laptops/nli_supervised_in_domain_laptops_MNLI-base_I_felt_696.ipynb",
      "parameters": {
        "experiment_id": "nli_supervised_in_domain_laptops_MNLI-base_I_felt_696",
        "neg_prompt_indexes": [
          1
        ],
        "nli_model_path": "textattack/bert-base-uncased-MNLI",
        "pos_prompt_indexes": [
          0
        ],
        "random_seed": 696,
        "sentiment_prompts": [
          "I felt the {aspect} was good.",
          "I felt the {aspect} was bad."
        ],
        "testing_batch_size": 8,
        "testing_domain": "laptops",
        "training_batch_size": 8,
        "training_domain": "laptops"
      },
      "start_time": "2021-04-14T09:17:42.825618",
      "version": "2.3.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff18e566b3cb429d80ed0daeecee43d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c1f52eea0df4a858577f09cd15d0207",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e3c9465b9f384baf9bddec1c7ba836eb",
              "IPY_MODEL_7ef8dcb601ad4029ba17d3a8676b9351"
            ]
          }
        },
        "2c1f52eea0df4a858577f09cd15d0207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3c9465b9f384baf9bddec1c7ba836eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_910505c16ac74ce098c906d4969d009d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 80,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 80,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b268439aa0ca46fbbd4767312e29a695"
          }
        },
        "7ef8dcb601ad4029ba17d3a8676b9351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad13ce441cd742c3ab10a3cab9795537",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 80/80 [00:43&lt;00:00,  1.82it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3bd6a93760264557b65379842084e53b"
          }
        },
        "910505c16ac74ce098c906d4969d009d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b268439aa0ca46fbbd4767312e29a695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad13ce441cd742c3ab10a3cab9795537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3bd6a93760264557b65379842084e53b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYSFmGrp2wSp"
      },
      "source": [
        ""
      ],
      "id": "yYSFmGrp2wSp",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvZa9Z3V2eGK"
      },
      "source": [
        ""
      ],
      "id": "NvZa9Z3V2eGK",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2dd8e3a",
        "papermill": {
          "duration": 0.099569,
          "end_time": "2021-04-14T09:17:44.356246",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.256677",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Initial Setups"
      ],
      "id": "b2dd8e3a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09036ef8",
        "papermill": {
          "duration": 0.070817,
          "end_time": "2021-04-14T09:17:44.498175",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.427358",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## (Google Colab use only)"
      ],
      "id": "09036ef8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:44.656950Z",
          "iopub.status.busy": "2021-04-14T09:17:44.656291Z",
          "iopub.status.idle": "2021-04-14T09:17:44.660609Z",
          "shell.execute_reply": "2021-04-14T09:17:44.660079Z"
        },
        "id": "1e81b28a",
        "papermill": {
          "duration": 0.091994,
          "end_time": "2021-04-14T09:17:44.660753",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.568759",
          "status": "completed"
        },
        "tags": [],
        "outputId": "af411526-f18b-4037-90e6-e887b19ed207"
      },
      "source": [
        "# Use Google Colab\n",
        "use_colab = True\n",
        "\n",
        "# Is this notebook running on Colab?\n",
        "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
        "# should be available in this environment\n",
        "\n",
        "# Previous version used importlib, but we could do the same thing with\n",
        "# just attempting to import google.colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    colab_available = True\n",
        "except:\n",
        "    colab_available = False\n",
        "\n",
        "if use_colab and colab_available:\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # cd to the appropriate working directory under my Google Drive\n",
        "    %cd '/content/drive/My Drive/ATSC'\n",
        "    \n",
        "    # Install packages specified in requirements\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # List the directory contents\n",
        "    !ls"
      ],
      "id": "1e81b28a",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/ATSC\n",
            "Requirement already satisfied: transformers==4.3.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (4.3.3)\n",
            "Requirement already satisfied: datasets==1.2.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.2.1)\n",
            "Requirement already satisfied: pytokenizations==0.7.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.7.2)\n",
            "Requirement already satisfied: spacy==2.3.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.3.5)\n",
            "Requirement already satisfied: en_core_web_sm from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.2.5)\n",
            "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.7.1)\n",
            "Requirement already satisfied: scikit-learn==0.24.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.24.1)\n",
            "Requirement already satisfied: seaborn==0.11.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.11.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (4.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 1)) (20.9)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (0.70.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (1.1.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (0.3.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (56.1.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (0.8.2)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (7.4.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->-r requirements.txt (line 6)) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 7)) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.11.1->-r requirements.txt (line 8)) (3.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.3.3->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3->-r requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1->-r requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1->-r requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn==0.11.1->-r requirements.txt (line 8)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn==0.11.1->-r requirements.txt (line 8)) (1.3.1)\n",
            " apex-master.zip\n",
            " baseline\n",
            " bert_base_cache\n",
            " checkpoint-1210520\n",
            " checkpoint-553363.zip\n",
            " dataset_cache\n",
            "'dataset_cache (1)'\n",
            " dataset_files\n",
            " dataset_scripts\n",
            " GPT2\n",
            " gpt2_amazon\n",
            " gpt2_cache\n",
            " MLM\n",
            " NLI\n",
            " nli-checkpoint-epoch2\n",
            " nli_files.txt\n",
            " NLIResults\n",
            " prompt_lr_atsc_single_prompt_the_aspect_gpt-2_yelp_restaurants\n",
            " requirements.txt\n",
            " semeval_data_files\n",
            " smart_mlm_yelp_500k_15percent.ipynb\n",
            " utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b2be680",
        "papermill": {
          "duration": 0.071744,
          "end_time": "2021-04-14T09:17:44.804138",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.732394",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Experiment parameters"
      ],
      "id": "8b2be680"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIpbwIm11WT-"
      },
      "source": [
        "import torch\n",
        "class SinglePromptLogitSentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, lm, num_class, pseudo_label_words, target_token_id=-1):\n",
        "        super(SinglePromptLogitSentimentClassificationHead, self).__init__()\n",
        "\n",
        "        self.num_class = num_class\n",
        "        self.pseudo_label_words = pseudo_label_words\n",
        "        self.target_token_id = target_token_id\n",
        "\n",
        "        self.lm = lm\n",
        "        \n",
        "        # Is self.lm BERT or GPT-2?\n",
        "        if self.lm.config.architectures[0].startswith('Bert'):\n",
        "            # if self.lm is BERT, then mask_token_id should be specified\n",
        "            assert self.target_token_id != -1\n",
        "            self.lm_type = 'bert'\n",
        "        elif self.lm.config.architectures[0].startswith('GPT2'):\n",
        "            self.lm_type = 'gpt2'\n",
        "        else:\n",
        "            raise Exception('Unsupported language model type.')\n",
        "            \n",
        "        print(\"Detected LM type:\", self.lm_type)\n",
        "\n",
        "    def forward(self, reviews_and_prompts):\n",
        "\n",
        "        if self.lm_type == 'bert':\n",
        "            # Figures out where the mask token was placed\n",
        "            target_indexes = (reviews_and_prompts.data[\"input_ids\"] == self.target_token_id)\n",
        "\n",
        "            lm_outputs = self.lm(**reviews_and_prompts)\n",
        "\n",
        "            outputs = lm_outputs.logits[target_indexes]\n",
        "        \n",
        "            outputs = outputs[:, self.pseudo_label_words]\n",
        "            \n",
        "        elif self.lm_type == 'gpt2':\n",
        "            \n",
        "            outputs = []\n",
        "            \n",
        "            for example in reviews_and_prompts:\n",
        "                lm_outputs = self.lm(**example, return_dict=True)\n",
        "                \n",
        "                lm_predictions = lm_outputs.logits[0, len(example['input_ids'][0]) - 1, self.pseudo_label_words]\n",
        "                \n",
        "                outputs.append(lm_predictions)\n",
        "\n",
        "            outputs = torch.stack(outputs, dim=0)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class MultiPromptSentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, lm, num_class, num_prompts, target_token_id=-1):\n",
        "        super(MultiPromptSentimentClassificationHead, self).__init__()\n",
        "\n",
        "        self.num_class = num_class\n",
        "        self.num_prompts = num_prompts\n",
        "        self.target_token_id = target_token_id\n",
        "\n",
        "        self.lm = lm\n",
        "        \n",
        "        # Is self.lm BERT or GPT-2?\n",
        "        if self.lm.config.architectures[0].startswith('Bert'):\n",
        "            # if self.lm is BERT, then mask_token_id should be specified\n",
        "            assert self.target_token_id != -1\n",
        "            self.lm_type = 'bert'\n",
        "        elif self.lm.config.architectures[0].startswith('GPT2'):\n",
        "            self.lm_type = 'gpt2'\n",
        "        else:\n",
        "            raise Exception('Unsupported language model type.')\n",
        "\n",
        "        print(\"Detected LM type:\", self.lm_type)\n",
        "\n",
        "        # Linear layer\n",
        "        self.linear = torch.nn.Linear(\n",
        "            self.num_prompts * self.lm.config.hidden_size, self.num_class)\n",
        "\n",
        "    def forward(self, reviews_and_prompts):\n",
        "\n",
        "        # Extract hidden states and feed them to self.linear\n",
        "        outputs = []\n",
        "\n",
        "        lr_inputs_batch = []\n",
        "\n",
        "        # Figures out where the mask token was placed\n",
        "        if self.lm_type == 'bert':\n",
        "            # For BERT, we need to find the token in each input with [MASK]\n",
        "            target_indexes = torch.nonzero(\n",
        "                reviews_and_prompts.data[\"input_ids\"] == self.target_token_id)[:, 1]\n",
        "\n",
        "            lm_outputs = self.lm(**reviews_and_prompts, output_hidden_states=True)\n",
        "\n",
        "            real_batch_size = len(reviews_and_prompts.data[\"input_ids\"]) // self.num_prompts\n",
        "\n",
        "        elif self.lm_type == 'gpt2':\n",
        "            lm_outputs = []\n",
        "            target_indexes = []\n",
        "\n",
        "            # For GPT-2, we need to find the spot right after the input text\n",
        "            for example in reviews_and_prompts:\n",
        "                target_indexes.append(len(example['input_ids'][0]) - 1)\n",
        "\n",
        "                lm_outputs.append(self.lm(**example, output_hidden_states=True))\n",
        "\n",
        "            real_batch_size = len(reviews_and_prompts) // self.num_prompts\n",
        "                \n",
        "        for i in range(real_batch_size):\n",
        "            # Create an input to self.linear by\n",
        "            # concatenating last hidden states for this review\n",
        "            lr_input = []\n",
        "\n",
        "            for j in range(self.num_prompts):\n",
        "                if self.lm_type == 'bert':\n",
        "                    lr_input.append(lm_outputs[\"hidden_states\"][-1][i+real_batch_size*j][target_indexes[i+real_batch_size*j]])\n",
        "                elif self.lm_type == 'gpt2':\n",
        "                    lr_input.append(lm_outputs[i+real_batch_size*j][\"hidden_states\"][-1][0][target_indexes[i+real_batch_size*j]])\n",
        "                    \n",
        "            lr_input = torch.cat(lr_input, dim=0)\n",
        "\n",
        "            lr_inputs_batch.append(lr_input)\n",
        "\n",
        "        lr_inputs_batch = torch.stack(lr_inputs_batch)\n",
        "\n",
        "        outputs = self.linear(lr_inputs_batch)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class NoPromptSentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, lm, num_class):\n",
        "        super(NoPromptSentimentClassificationHead, self).__init__()\n",
        "\n",
        "        self.num_class = num_class\n",
        "\n",
        "        self.lm = lm\n",
        "\n",
        "        self.linear = torch.nn.Linear(\n",
        "            self.lm.config.hidden_size, self.num_class)\n",
        "\n",
        "    def forward(self, reviews_and_prompts):\n",
        "\n",
        "        lm_outputs = self.lm(**reviews_and_prompts, output_hidden_states=True)\n",
        "\n",
        "        # Last hidden state for [CLS] token\n",
        "        last_hidden_state_cls = lm_outputs[\"hidden_states\"][-1][:, 0, :]\n",
        "        \n",
        "        outputs = self.linear(last_hidden_state_cls)\n",
        "\n",
        "        return outputs\n",
        "    \n",
        "class NLISentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, nli_model, num_prompts, pos_prompt_indexes, neg_prompt_indexes):\n",
        "        super(NLISentimentClassificationHead, self).__init__()\n",
        "        \n",
        "        self.num_prompts = num_prompts\n",
        "        self.nli_model = nli_model\n",
        "        \n",
        "        self.pos_prompt_indexes = pos_prompt_indexes\n",
        "        self.neg_prompt_indexes = neg_prompt_indexes\n",
        "        \n",
        "    def forward(self, reviews_and_prompts):\n",
        "        \n",
        "        nli_output = self.nli_model(**reviews_and_prompts)[\"logits\"]\n",
        "\n",
        "        outputs = torch.Tensor().to(self.nli_model.device)\n",
        "\n",
        "        # Text Attack NLI Labels: 0-> Contradiction, 1-> Entailment, 2-> Neutral\n",
        "        # Sentiment Polarity Labels: 0-> Positive, 1-> Negative, 2-> Neutral\n",
        "        for i in range(len(nli_output)//self.num_prompts):\n",
        "            prompts_batch = nli_output[i*self.num_prompts:(i+1)*self.num_prompts]\n",
        "\n",
        "            pos_logit = torch.mean(prompts_batch[self.pos_prompt_indexes], dim=0)[1]\n",
        "\n",
        "            neg_logit = torch.mean(prompts_batch[self.neg_prompt_indexes], dim=0)[1]\n",
        "\n",
        "            neu_logit = torch.mean(prompts_batch, dim=0)[2]\n",
        "\n",
        "            pred_logits = torch.stack([pos_logit, neg_logit, neu_logit])\n",
        "            pred_logits = torch.reshape(pred_logits, (1,-1))\n",
        "\n",
        "            outputs = torch.cat([outputs, pred_logits])\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class NLIMinSentimentClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, nli_model, num_prompts, pos_prompt_indexes, neg_prompt_indexes):\n",
        "        super(NLIMinSentimentClassificationHead, self).__init__()\n",
        "        \n",
        "        self.num_prompts = num_prompts\n",
        "        self.nli_model = nli_model\n",
        "        \n",
        "        self.pos_prompt_indexes = pos_prompt_indexes\n",
        "        self.neg_prompt_indexes = neg_prompt_indexes\n",
        "        \n",
        "    def forward(self, reviews_and_prompts):\n",
        "        \n",
        "        nli_output = self.nli_model(**reviews_and_prompts)[\"logits\"]\n",
        "\n",
        "        outputs = torch.Tensor().to(self.nli_model.device)\n",
        "\n",
        "        # Text Attack NLI Labels: 0-> Contradiction, 1-> Entailment, 2-> Neutral\n",
        "        # Sentiment Polarity Labels: 0-> Positive, 1-> Negative, 2-> Neutral\n",
        "        for i in range(len(nli_output)//self.num_prompts):\n",
        "            prompts_batch = nli_output[i*self.num_prompts:(i+1)*self.num_prompts]\n",
        "\n",
        "            pos_logit = torch.mean(prompts_batch[self.pos_prompt_indexes], dim=0)[1]\n",
        "\n",
        "            neg_logit = torch.mean(prompts_batch[self.neg_prompt_indexes], dim=0)[1]\n",
        "\n",
        "            neu_logit = torch.min(prompts_batch, dim=0)[0][2]\n",
        "\n",
        "            pred_logits = torch.stack([pos_logit, neg_logit, neu_logit])\n",
        "            pred_logits = torch.reshape(pred_logits, (1,-1))\n",
        "\n",
        "            outputs = torch.cat([outputs, pred_logits])\n",
        "\n",
        "        return outputs\n"
      ],
      "id": "DIpbwIm11WT-",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:44.957547Z",
          "iopub.status.busy": "2021-04-14T09:17:44.956864Z",
          "iopub.status.idle": "2021-04-14T09:17:44.960465Z",
          "shell.execute_reply": "2021-04-14T09:17:44.959837Z"
        },
        "id": "205c591d",
        "papermill": {
          "duration": 0.084988,
          "end_time": "2021-04-14T09:17:44.960595",
          "exception": false,
          "start_time": "2021-04-14T09:17:44.875607",
          "status": "completed"
        },
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "\n",
        "# We will use the following string ID to identify this particular (training) experiments\n",
        "# in directory paths and other settings\n",
        "experiment_id = 'supervised_nli_single_prompt_1_in_domain_restaurant_MNLI_base_seed_696'\n",
        "\n",
        "# Random seed\n",
        "random_seed = 696\n",
        "\n",
        "# path to pretrained nli model folder or the string \"textattack/bert-base-uncased-MNLI\"\n",
        "nli_model_path = \"textattack/bert-base-uncased-MNLI\"\n",
        "\n",
        "# Prompts to be added to the end of each review text\n",
        "sentiment_prompts = [\n",
        "    \"The {aspect} is good.\",\n",
        "    \"The {aspect} is bad.\"]\n",
        "\n",
        "#index of the prompts in the sentiment_prompts by polarity for later grouping\n",
        "pos_prompt_indexes = [0]\n",
        "neg_prompt_indexes = [1]\n",
        "\n",
        "#What datasets to be used for training and testing loops\n",
        "training_domain = \"restaurants\"\n",
        "testing_domain = \"restaurants\"\n",
        "\n",
        "# Training settings\n",
        "training_epochs = 20\n",
        "training_batch_size = 8\n",
        "training_learning_rate = 2e-5\n",
        "training_weight_decay = 0.01\n",
        "training_warmup_steps_duration = 0.1\n",
        "training_best_model_criterion = 'train_loss'\n",
        "\n",
        "training_lm_freeze = False\n",
        "\n",
        "validation_enabled = False\n",
        "validation_dataset_proportion = 0.2\n",
        "validation_batch_size = 8\n",
        "\n",
        "testing_batch_size = 32"
      ],
      "id": "205c591d",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:45.125761Z",
          "iopub.status.busy": "2021-04-14T09:17:45.125025Z",
          "iopub.status.idle": "2021-04-14T09:17:45.128050Z",
          "shell.execute_reply": "2021-04-14T09:17:45.127424Z"
        },
        "papermill": {
          "duration": 0.08669,
          "end_time": "2021-04-14T09:17:45.128255",
          "exception": false,
          "start_time": "2021-04-14T09:17:45.041565",
          "status": "completed"
        },
        "tags": [
          "injected-parameters"
        ],
        "id": "33158748"
      },
      "source": [
        "# Parameters\n",
        "experiment_id = \"nli_few_shot_in_domain_laptops_256_MNLI-base_I_like_696\"\n",
        "random_seed = 696\n",
        "nli_model_path = \"textattack/bert-base-uncased-MNLI\"\n",
        "sentiment_prompts = [\n",
        "    \"The {aspect} made me feel good.\",\n",
        "    \"The {aspect} made me feel bad.\",\n",
        "]\n",
        "pos_prompt_indexes = [0]\n",
        "neg_prompt_indexes = [1]\n",
        "training_domain = \"laptops\"\n",
        "testing_batch_size = 8\n",
        "testing_domain = \"laptops\"\n",
        "training_batch_size = 8\n"
      ],
      "id": "33158748",
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "169e034b",
        "papermill": {
          "duration": 0.059185,
          "end_time": "2021-04-14T09:17:45.258934",
          "exception": false,
          "start_time": "2021-04-14T09:17:45.199749",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Package imports"
      ],
      "id": "169e034b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:45.381681Z",
          "iopub.status.busy": "2021-04-14T09:17:45.381034Z",
          "iopub.status.idle": "2021-04-14T09:17:48.668262Z",
          "shell.execute_reply": "2021-04-14T09:17:48.669304Z"
        },
        "id": "18d534de",
        "papermill": {
          "duration": 3.355855,
          "end_time": "2021-04-14T09:17:48.669607",
          "exception": false,
          "start_time": "2021-04-14T09:17:45.313752",
          "status": "completed"
        },
        "tags": [],
        "outputId": "1ad432de-2e2c-4734-b31b-ea755cf228ff"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import copy\n",
        "import inspect\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "import datasets\n",
        "import sklearn.metrics\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import tqdm\n",
        "\n",
        "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
        "parent_dir = os.path.dirname(current_dir)\n",
        "sys.path.append(parent_dir)\n",
        "\n",
        "import utils\n",
        "\n",
        "# Random seed settings\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "# cuBLAS reproducibility\n",
        "# https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
        "torch.set_deterministic(True)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# Print version information\n",
        "print(\"Python version: \" + sys.version)\n",
        "print(\"NumPy version: \" + np.__version__)\n",
        "print(\"PyTorch version: \" + torch.__version__)\n",
        "print(\"Transformers version: \" + transformers.__version__)"
      ],
      "id": "18d534de",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version: 3.7.10 (default, May  3 2021, 02:48:31) \n",
            "[GCC 7.5.0]\n",
            "NumPy version: 1.19.5\n",
            "PyTorch version: 1.7.1\n",
            "Transformers version: 4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78f1ee52",
        "papermill": {
          "duration": 0.067281,
          "end_time": "2021-04-14T09:17:48.839940",
          "exception": false,
          "start_time": "2021-04-14T09:17:48.772659",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## PyTorch GPU settings"
      ],
      "id": "78f1ee52"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:50.767583Z",
          "iopub.status.busy": "2021-04-14T09:17:49.016404Z",
          "iopub.status.idle": "2021-04-14T09:17:50.771850Z",
          "shell.execute_reply": "2021-04-14T09:17:50.772413Z"
        },
        "id": "53d9ba9a",
        "papermill": {
          "duration": 1.862641,
          "end_time": "2021-04-14T09:17:50.772589",
          "exception": false,
          "start_time": "2021-04-14T09:17:48.909948",
          "status": "completed"
        },
        "tags": [],
        "outputId": "e3e84a81-0dc4-4d3d-855d-11001e2c82d5"
      },
      "source": [
        "\n",
        "if torch.cuda.is_available():    \n",
        "    torch_device = torch.device('cuda')\n",
        "\n",
        "    # Set this to True to make your output immediately reproducible\n",
        "    # Note: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "    # Disable 'benchmark' mode: Set this False if you want to measure running times more fairly\n",
        "    # Note: https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    \n",
        "    # Faster Host to GPU copies with page-locked memory\n",
        "    use_pin_memory = True\n",
        "    \n",
        "    # Number of compute devices to be used for training\n",
        "    training_device_count = torch.cuda.device_count()\n",
        "\n",
        "    # CUDA libraries version information\n",
        "    print(\"CUDA Version: \" + str(torch.version.cuda))\n",
        "    print(\"cuDNN Version: \" + str(torch.backends.cudnn.version()))\n",
        "    print(\"CUDA Device Name: \" + str(torch.cuda.get_device_name()))\n",
        "    print(\"CUDA Capabilities: \"+ str(torch.cuda.get_device_capability()))\n",
        "    print(\"Number of CUDA devices: \"+ str(training_device_count))\n",
        "    \n",
        "else:\n",
        "    torch_device = torch.device('cpu')\n",
        "    use_pin_memory = False\n",
        "    \n",
        "    # Number of compute devices to be used for training\n",
        "    training_device_count = 1\n",
        "\n",
        "print()\n",
        "print(\"PyTorch device selected:\", torch_device)"
      ],
      "id": "53d9ba9a",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Version: 10.2\n",
            "cuDNN Version: 7605\n",
            "CUDA Device Name: Tesla T4\n",
            "CUDA Capabilities: (7, 5)\n",
            "Number of CUDA devices: 1\n",
            "\n",
            "PyTorch device selected: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30f1f1cb",
        "papermill": {
          "duration": 0.072829,
          "end_time": "2021-04-14T09:17:50.920232",
          "exception": false,
          "start_time": "2021-04-14T09:17:50.847403",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Prepare Datasets for Prompt-based Classifier"
      ],
      "id": "30f1f1cb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b25dbc88",
        "papermill": {
          "duration": 0.072759,
          "end_time": "2021-04-14T09:17:51.066279",
          "exception": false,
          "start_time": "2021-04-14T09:17:50.993520",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Load the SemEval dataset"
      ],
      "id": "b25dbc88"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:51.227509Z",
          "iopub.status.busy": "2021-04-14T09:17:51.226811Z",
          "iopub.status.idle": "2021-04-14T09:17:51.948638Z",
          "shell.execute_reply": "2021-04-14T09:17:51.947637Z"
        },
        "id": "a4e71c29",
        "papermill": {
          "duration": 0.805682,
          "end_time": "2021-04-14T09:17:51.948940",
          "exception": false,
          "start_time": "2021-04-14T09:17:51.143258",
          "status": "completed"
        },
        "tags": [],
        "outputId": "48002530-be36-470d-975b-ea607d926c28"
      },
      "source": [
        "# Load semeval for both domains\n",
        "laptop_semeval_dataset = datasets.load_dataset(\n",
        "    os.path.abspath('./dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
        "    data_files={\n",
        "        'test': './dataset_files/semeval_2014/Laptops_Test_Gold.xml',\n",
        "        'train': './dataset_files/semeval_2014/Laptop_Train_v2.xml',\n",
        "    },\n",
        "    cache_dir='./dataset_cache')\n",
        "\n",
        "restaurant_semeval_dataset = datasets.load_dataset(\n",
        "    os.path.abspath('./dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
        "    data_files={\n",
        "        'test': './dataset_files/semeval_2014/Restaurants_Test_Gold.xml',\n",
        "        'train': './dataset_files/semeval_2014/Restaurants_Train_v2.xml',\n",
        "    },\n",
        "    cache_dir='./dataset_cache')"
      ],
      "id": "a4e71c29",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset sem_eval2014_task4_dataset (./dataset_cache/sem_eval2014_task4_dataset/default-2ba098669778f075/0.0.1/f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969)\n",
            "Using custom data configuration default\n",
            "Reusing dataset sem_eval2014_task4_dataset (./dataset_cache/sem_eval2014_task4_dataset/default-00707989ebea381d/0.0.1/f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.127349Z",
          "iopub.status.busy": "2021-04-14T09:17:52.126410Z",
          "iopub.status.idle": "2021-04-14T09:17:52.128934Z",
          "shell.execute_reply": "2021-04-14T09:17:52.129482Z"
        },
        "id": "234dcdac",
        "papermill": {
          "duration": 0.081917,
          "end_time": "2021-04-14T09:17:52.129628",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.047711",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "dataset_dic_train = {\n",
        "    \"laptops\": laptop_semeval_dataset['train'],\n",
        "    \"restaurants\": restaurant_semeval_dataset['train']\n",
        "}\n",
        "\n",
        "dataset_dic_test = {\n",
        "    \"laptops\": laptop_semeval_dataset['test'],\n",
        "    \"restaurants\": restaurant_semeval_dataset['test']\n",
        "}\n"
      ],
      "id": "234dcdac",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.284055Z",
          "iopub.status.busy": "2021-04-14T09:17:52.283164Z",
          "iopub.status.idle": "2021-04-14T09:17:52.285775Z",
          "shell.execute_reply": "2021-04-14T09:17:52.286325Z"
        },
        "papermill": {
          "duration": 0.081159,
          "end_time": "2021-04-14T09:17:52.286474",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.205315",
          "status": "completed"
        },
        "tags": [],
        "id": "3b556c52"
      },
      "source": [
        "# The dataset chosen for training and testing\n",
        "train_set = dataset_dic_train[training_domain]\n",
        "test_set = dataset_dic_test[testing_domain]"
      ],
      "id": "3b556c52",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42aeac01",
        "papermill": {
          "duration": 0.074267,
          "end_time": "2021-04-14T09:17:52.434905",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.360638",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Train-validation split"
      ],
      "id": "42aeac01"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.589122Z",
          "iopub.status.busy": "2021-04-14T09:17:52.588365Z",
          "iopub.status.idle": "2021-04-14T09:17:52.592239Z",
          "shell.execute_reply": "2021-04-14T09:17:52.591606Z"
        },
        "id": "c5201e50",
        "papermill": {
          "duration": 0.082863,
          "end_time": "2021-04-14T09:17:52.592369",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.509506",
          "status": "completed"
        },
        "tags": [],
        "outputId": "0daa0e93-439b-4eec-b968-999ca4f1ea50"
      },
      "source": [
        "# Training set size after validation split\n",
        "if validation_enabled:\n",
        "    new_train_dataset_size = int(len(train_set) * (1 - validation_dataset_proportion))\n",
        "    new_valid_dataset_size = len(train_set) - new_train_dataset_size\n",
        "    print(\"Training dataset after split:\", new_train_dataset_size)\n",
        "    print(\"Validation dataset after split:\", new_train_dataset_size)\n",
        "else:\n",
        "    new_train_dataset_size = len(train_set)\n",
        "    print(\"Training dataset size:\", new_train_dataset_size)"
      ],
      "id": "c5201e50",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset size: 2313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.730472Z",
          "iopub.status.busy": "2021-04-14T09:17:52.729971Z",
          "iopub.status.idle": "2021-04-14T09:17:52.787818Z",
          "shell.execute_reply": "2021-04-14T09:17:52.787292Z"
        },
        "id": "8710a9bd",
        "papermill": {
          "duration": 0.120927,
          "end_time": "2021-04-14T09:17:52.787955",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.667028",
          "status": "completed"
        },
        "tags": [],
        "outputId": "884952fb-2492-4fde-a870-3b71295d5769"
      },
      "source": [
        "train_set = train_set.shuffle(seed=random_seed)\n",
        "\n",
        "new_train_set = train_set.select(indices=np.arange(new_train_dataset_size))\n",
        "\n",
        "if validation_enabled:\n",
        "    new_valid_set = train_set.select(\n",
        "        indices=np.arange(\n",
        "            new_train_dataset_size,\n",
        "            new_train_dataset_size + new_valid_dataset_size))"
      ],
      "id": "8710a9bd",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached shuffled indices for dataset at ./dataset_cache/sem_eval2014_task4_dataset/default-2ba098669778f075/0.0.1/f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969/cache-de8ce8ac91817d47.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:52.913145Z",
          "iopub.status.busy": "2021-04-14T09:17:52.912611Z",
          "iopub.status.idle": "2021-04-14T09:17:52.915730Z",
          "shell.execute_reply": "2021-04-14T09:17:52.915257Z"
        },
        "id": "60a082f3",
        "papermill": {
          "duration": 0.06474,
          "end_time": "2021-04-14T09:17:52.915829",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.851089",
          "status": "completed"
        },
        "tags": [],
        "outputId": "2c5cdcec-8059-474e-aab3-03d42ce155a4"
      },
      "source": [
        "print(new_train_set[0])"
      ],
      "id": "60a082f3",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'aspect': 'loads', 'sentiment': 2, 'text': 'Once I removed all the software the laptop loads in 15-20 seconds.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1865dbeb",
        "papermill": {
          "duration": 0.059399,
          "end_time": "2021-04-14T09:17:53.035203",
          "exception": false,
          "start_time": "2021-04-14T09:17:52.975804",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Supervised ATSC with Prompts + Logistic Regression Head"
      ],
      "id": "1865dbeb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08dca259",
        "papermill": {
          "duration": 0.057453,
          "end_time": "2021-04-14T09:17:53.150677",
          "exception": false,
          "start_time": "2021-04-14T09:17:53.093224",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Load the pretrained LM"
      ],
      "id": "08dca259"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:53.270315Z",
          "iopub.status.busy": "2021-04-14T09:17:53.269643Z",
          "iopub.status.idle": "2021-04-14T09:17:58.431562Z",
          "shell.execute_reply": "2021-04-14T09:17:58.432583Z"
        },
        "id": "56a24d11",
        "papermill": {
          "duration": 5.224628,
          "end_time": "2021-04-14T09:17:58.432932",
          "exception": false,
          "start_time": "2021-04-14T09:17:53.208304",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Load pretrained language model\n",
        "nli_model = transformers.AutoModelForSequenceClassification.from_pretrained(nli_model_path)\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-MNLI\", cache_dir='../bert_base_cache')"
      ],
      "id": "56a24d11",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:58.618927Z",
          "iopub.status.busy": "2021-04-14T09:17:58.618342Z",
          "iopub.status.idle": "2021-04-14T09:17:58.621535Z",
          "shell.execute_reply": "2021-04-14T09:17:58.621050Z"
        },
        "papermill": {
          "duration": 0.079367,
          "end_time": "2021-04-14T09:17:58.621647",
          "exception": false,
          "start_time": "2021-04-14T09:17:58.542280",
          "status": "completed"
        },
        "tags": [],
        "id": "3e1bfc3f"
      },
      "source": [
        "# Freeze all layers in lm.\n",
        "if training_lm_freeze:\n",
        "    for param in nli_model.parameters():\n",
        "        param.requires_grad = False"
      ],
      "id": "3e1bfc3f",
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:17:58.748044Z",
          "iopub.status.busy": "2021-04-14T09:17:58.747553Z",
          "iopub.status.idle": "2021-04-14T09:18:01.944791Z",
          "shell.execute_reply": "2021-04-14T09:18:01.945802Z"
        },
        "papermill": {
          "duration": 3.262784,
          "end_time": "2021-04-14T09:18:01.946086",
          "exception": false,
          "start_time": "2021-04-14T09:17:58.683302",
          "status": "completed"
        },
        "tags": [],
        "id": "c5220e7a"
      },
      "source": [
        "classifier = NLISentimentClassificationHead(\n",
        "                    nli_model = nli_model,\n",
        "                    num_prompts = len(sentiment_prompts),\n",
        "                    pos_prompt_indexes = pos_prompt_indexes,\n",
        "                    neg_prompt_indexes = neg_prompt_indexes\n",
        "                    )\n",
        "classifier_model = classifier.to(torch_device)"
      ],
      "id": "c5220e7a",
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72da7aad",
        "papermill": {
          "duration": 0.078495,
          "end_time": "2021-04-14T09:18:02.134812",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.056317",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training settings"
      ],
      "id": "72da7aad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:18:02.297951Z",
          "iopub.status.busy": "2021-04-14T09:18:02.297293Z",
          "iopub.status.idle": "2021-04-14T09:18:02.301372Z",
          "shell.execute_reply": "2021-04-14T09:18:02.301889Z"
        },
        "papermill": {
          "duration": 0.090522,
          "end_time": "2021-04-14T09:18:02.302042",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.211520",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af6620a2",
        "outputId": "f082aa22-b0d7-4fee-f81c-f6ba79f0a738"
      },
      "source": [
        "# How many training steps would we have?\n",
        "approx_total_training_steps = len(new_train_set) // training_batch_size * training_epochs\n",
        "\n",
        "print(\"There will be approximately %d training steps.\" % approx_total_training_steps)\n",
        "\n",
        "# Let's have warmups for the first (training_warmup_steps_duration)% of steps.\n",
        "training_warmup_steps = int(approx_total_training_steps * training_warmup_steps_duration)\n",
        "\n",
        "print(\"Warmup steps:\", training_warmup_steps)"
      ],
      "id": "af6620a2",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There will be approximately 5780 training steps.\n",
            "Warmup steps: 578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:18:02.469038Z",
          "iopub.status.busy": "2021-04-14T09:18:02.468393Z",
          "iopub.status.idle": "2021-04-14T09:18:02.623352Z",
          "shell.execute_reply": "2021-04-14T09:18:02.624314Z"
        },
        "id": "85799efc",
        "papermill": {
          "duration": 0.244883,
          "end_time": "2021-04-14T09:18:02.624583",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.379700",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    new_train_set, batch_size=training_batch_size,\n",
        "    shuffle=True, pin_memory=use_pin_memory)\n",
        "\n",
        "if validation_enabled:\n",
        "    validation_dataloader = torch.utils.data.DataLoader(\n",
        "        new_valid_set, batch_size=validation_batch_size, pin_memory=use_pin_memory)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = transformers.AdamW(\n",
        "    classifier.parameters(),\n",
        "    lr=training_learning_rate,\n",
        "    weight_decay=training_weight_decay)\n",
        "\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=training_warmup_steps,\n",
        "    num_training_steps=len(new_train_set) * training_epochs,\n",
        ")\n",
        "\n",
        "# The directory to save the best version of the head\n",
        "trained_model_directory = os.path.join('..', 'trained_models', experiment_id)\n",
        "\n",
        "shutil.rmtree(trained_model_directory, ignore_errors=True)\n",
        "os.makedirs(trained_model_directory)"
      ],
      "id": "85799efc",
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T09:18:02.806888Z",
          "iopub.status.busy": "2021-04-14T09:18:02.806235Z",
          "iopub.status.idle": "2021-04-14T09:18:02.809906Z",
          "shell.execute_reply": "2021-04-14T09:18:02.809300Z"
        },
        "id": "2164d6dc",
        "papermill": {
          "duration": 0.090842,
          "end_time": "2021-04-14T09:18:02.810040",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.719198",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def compute_metrics(predictions, labels):\n",
        "    preds = predictions.argmax(-1)\n",
        "\n",
        "    precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
        "        y_true=labels, y_pred=preds, labels=[0,1,2], average='macro')\n",
        "\n",
        "    acc = sklearn.metrics.accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "id": "2164d6dc",
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da810758",
        "papermill": {
          "duration": 0.078398,
          "end_time": "2021-04-14T09:18:02.966537",
          "exception": false,
          "start_time": "2021-04-14T09:18:02.888139",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training loop"
      ],
      "id": "da810758"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32555d11",
        "papermill": {
          "duration": 0.106487,
          "end_time": "2021-04-14T10:25:54.578808",
          "exception": false,
          "start_time": "2021-04-14T10:25:54.472321",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Evaluation with in-domain test set"
      ],
      "id": "32555d11"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T10:25:54.738868Z",
          "iopub.status.busy": "2021-04-14T10:25:54.738386Z",
          "iopub.status.idle": "2021-04-14T10:25:54.741146Z",
          "shell.execute_reply": "2021-04-14T10:25:54.741526Z"
        },
        "id": "8442276c",
        "papermill": {
          "duration": 0.085244,
          "end_time": "2021-04-14T10:25:54.741640",
          "exception": false,
          "start_time": "2021-04-14T10:25:54.656396",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ef7cb7-ac2e-46b6-daa2-4bc4bb9fcfcb"
      },
      "source": [
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=testing_batch_size, pin_memory=use_pin_memory)\n",
        "# Locate the weight file.\n",
        "trained_model_directory = os.path.join('NLIResults', experiment_id)\n",
        "\n",
        "saved_weights_name = ''\n",
        "\n",
        "for fname in os.listdir(trained_model_directory):\n",
        "    if fname.startswith('epoch'):\n",
        "        saved_weights_name = fname\n",
        "        break\n",
        "\n",
        "print(\"Loading\", saved_weights_name)"
      ],
      "id": "8442276c",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading epoch_18.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-14T10:25:54.910301Z",
          "iopub.status.busy": "2021-04-14T10:25:54.909777Z",
          "iopub.status.idle": "2021-04-14T10:26:30.883459Z",
          "shell.execute_reply": "2021-04-14T10:26:30.882519Z"
        },
        "papermill": {
          "duration": 36.067047,
          "end_time": "2021-04-14T10:26:30.883703",
          "exception": false,
          "start_time": "2021-04-14T10:25:54.816656",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "ff18e566b3cb429d80ed0daeecee43d8",
            "2c1f52eea0df4a858577f09cd15d0207",
            "e3c9465b9f384baf9bddec1c7ba836eb",
            "7ef8dcb601ad4029ba17d3a8676b9351",
            "910505c16ac74ce098c906d4969d009d",
            "b268439aa0ca46fbbd4767312e29a695",
            "ad13ce441cd742c3ab10a3cab9795537",
            "3bd6a93760264557b65379842084e53b"
          ]
        },
        "id": "24ddd232",
        "outputId": "0ce3ac7a-8799-4def-ed55-250d87214b4b"
      },
      "source": [
        "\n",
        "# Load the best found head weights\n",
        "with torch.no_grad():\n",
        "    \n",
        "    classifier_model.load_state_dict(torch.load(os.path.join(os.path.join('NLIResults', experiment_id), saved_weights_name),map_location=torch_device))\n",
        "\n",
        "    classifier.eval()\n",
        "\n",
        "    predictions_test = torch.Tensor().to(torch_device)\n",
        "\n",
        "    labels_test = torch.Tensor().to(torch_device)\n",
        "\n",
        "    for batch_test in tqdm.notebook.tqdm(test_dataloader):\n",
        "\n",
        "        reviews_repeated = []\n",
        "        prompts_populated = []\n",
        "\n",
        "        for i in range(len(batch_test[\"text\"])):\n",
        "            \n",
        "            for prompt in sentiment_prompts:\n",
        "                reviews_repeated.append(batch_test[\"text\"][i])\n",
        "                prompts_populated.append(prompt.format(aspect=\"things\"))\n",
        "\n",
        "        batch_encoded = tokenizer(\n",
        "            reviews_repeated, prompts_populated,\n",
        "            padding='max_length', truncation='only_first', max_length=256,\n",
        "            return_tensors='pt')\n",
        "        \n",
        "        batch_encoded.to(torch_device)\n",
        "\n",
        "        nli_output = nli_model(**batch_encoded)[\"logits\"]\n",
        "\n",
        "        labels = batch_test[\"sentiment\"]\n",
        "        labels = labels.to(torch_device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = classifier(batch_encoded)\n",
        "        \n",
        "        predictions_test = torch.cat([predictions_test, outputs])\n",
        "        labels_test = torch.cat([labels_test, labels])\n",
        "\n",
        "    # Compute metrics\n",
        "    test_metrics = compute_metrics(predictions_test.cpu(), labels_test.cpu())\n",
        "    \n",
        "    print(test_metrics)"
      ],
      "id": "24ddd232",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff18e566b3cb429d80ed0daeecee43d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{'accuracy': 0.7053291536050157, 'f1': 0.663961457003064, 'precision': 0.6874908168035798, 'recall': 0.6606566897742456}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ab3d621",
        "papermill": {
          "duration": 0.100598,
          "end_time": "2021-04-14T10:26:31.118456",
          "exception": false,
          "start_time": "2021-04-14T10:26:31.017858",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Results visualization"
      ],
      "id": "9ab3d621"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "execution": {
          "iopub.execute_input": "2021-04-14T10:26:31.331369Z",
          "iopub.status.busy": "2021-04-14T10:26:31.330655Z",
          "iopub.status.idle": "2021-04-14T10:26:31.693819Z",
          "shell.execute_reply": "2021-04-14T10:26:31.694913Z"
        },
        "id": "40353e9f",
        "papermill": {
          "duration": 0.476879,
          "end_time": "2021-04-14T10:26:31.695265",
          "exception": false,
          "start_time": "2021-04-14T10:26:31.218386",
          "status": "completed"
        },
        "tags": [],
        "outputId": "89e4effd-7029-498d-d73a-3b0e4a0af079"
      },
      "source": [
        "# Calculate metrics and confusion matrix based upon predictions and true labels\n",
        "cm = sklearn.metrics.confusion_matrix(labels_test.cpu().detach().numpy(), predictions_test.cpu().detach().numpy().argmax(-1), labels=[0,1,2])\n",
        "\n",
        "df_cm = pd.DataFrame(\n",
        "    cm,\n",
        "    index=[i for i in [\"positive\", \"negative\", \"neutral\"]],\n",
        "    columns=[i for i in [\"positive\", \"negative\", \"neutral\"]])\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "ax = sn.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "\n",
        "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
        "plt.show()"
      ],
      "id": "40353e9f",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.100383,
          "end_time": "2021-04-14T10:26:31.929814",
          "exception": false,
          "start_time": "2021-04-14T10:26:31.829431",
          "status": "completed"
        },
        "tags": [],
        "id": "192b42b7"
      },
      "source": [
        ""
      ],
      "id": "192b42b7",
      "execution_count": 105,
      "outputs": []
    }
  ]
}