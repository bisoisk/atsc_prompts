{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "import datasets\n",
    "\n",
    "torch.cuda.is_available()\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "model_name = \"MLM_BERT-Base_Trained_on_Restaurant\"\n",
    "validate_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-uncased\", cache_dir='../bert_base_cache')\n",
    "model = transformers.AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\", cache_dir='../bert_base_cache')\n",
    "\n",
    "model = model.to(device=cuda)\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9b6d847dca00ea02\n",
      "Reusing dataset sem_eval2014_task4_dataset (../dataset_cache\\sem_eval2014_task4_dataset\\default-9b6d847dca00ea02\\0.0.1\\f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969)\n"
     ]
    }
   ],
   "source": [
    "semeval_laptop = datasets.load_dataset(\n",
    "    '../dataset_scripts/semeval2014_task4/semeval2014_task4.py',\n",
    "    data_files={\n",
    "        'test': r'C:\\Users\\ibirl\\Documents\\dsProjects\\zero_shot_atsc\\zero_shot_atsc\\dataset_files\\semeval_2014\\Laptops_Test_Gold.xml',\n",
    "        'train': r'C:\\Users\\ibirl\\Documents\\dsProjects\\zero_shot_atsc\\zero_shot_atsc\\dataset_files\\semeval_2014\\Laptop_Train_v2.xml'\n",
    "    },\n",
    "    cache_dir='../dataset_cache')\n",
    "\n",
    "semeval_restaurant = None\n",
    "\n",
    "if validate_model:\n",
    "    semeval_restaurant = datasets.load_dataset(\n",
    "        'dataset_scripts/semeval2014_task4/semeval2014_task4.py',\n",
    "        data_files={\n",
    "            'test': r'dataset_files\\semeval_2014\\Restaurants_Test_Gold.xml',\n",
    "            'train': r'dataset_files\\semeval_2014\\Restaurants_Train_v2.xml'\n",
    "        },\n",
    "        cache_dir='../dataset_cache')\n",
    "    \n",
    "    semeval_restaurant = semeval_restaurant[\"train\"]\n",
    "    \n",
    "semeval_laptop = semeval_laptop[\"train\"]\n",
    "\n",
    "\n",
    "#semeval_dataset = datasets.concatenate_datasets([semeval_laptop, semeval_restaurant])\n",
    "#print(semeval_dataset[0])\n",
    "#print(semeval_dataset[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompts = [\n",
    "    \"The {aspect} is [MASK].\",\n",
    "    \"I [MASK] the {aspect}.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../dataset_cache\\sem_eval2014_task4_dataset\\default-9b6d847dca00ea02\\0.0.1\\f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969\\cache-f03e2478987f984c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 2, 'prompt': 'The cord is [MASK].', 'review_id': '811f8505-81ea-11eb-8b93-7085c2c04498', 'text': 'I charge it at night and skip taking the cord with me because of the good battery life.'}\n",
      "4626\n"
     ]
    }
   ],
   "source": [
    "def add_prompts(reviews, prompts):\n",
    "\n",
    "    texts = []\n",
    "    sentiments = []\n",
    "    ids = []\n",
    "    aspect_prompts = []\n",
    "    \n",
    "    for i in range(len(reviews[\"aspect\"])):\n",
    "        \n",
    "        aspect = reviews[\"aspect\"][i]\n",
    "        text = reviews[\"text\"][i]\n",
    "        sentiment = reviews[\"sentiment\"][i]\n",
    "        \n",
    "        review_id = str(uuid.uuid1())\n",
    "        \n",
    "        for p in prompts:\n",
    "            aspect_prompt = p.format(aspect=aspect)\n",
    "\n",
    "            texts.append(text)\n",
    "            sentiments.append(sentiment)\n",
    "            ids.append(review_id)\n",
    "            aspect_prompts.append(aspect_prompt)\n",
    "\n",
    "    return {\"text\":texts, \"prompt\": aspect_prompts, \"label\": sentiments, \"review_id\": ids}\n",
    "\n",
    "prompt_dataset = semeval_laptop.map(\n",
    "    lambda e: add_prompts(e, sentiment_prompts),\n",
    "    remove_columns=semeval_laptop.column_names,\n",
    "    batched=True)\n",
    "\n",
    "if validate_model:\n",
    "    prompt_dataset_val = semeval_restaurant.map(\n",
    "        lambda e: add_prompts(e, sentiment_prompts),\n",
    "        remove_columns=semeval_laptop.column_names,\n",
    "        batched=True)\n",
    "\n",
    "print(prompt_dataset[0])\n",
    "print(len(prompt_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77dc86668bb548a68d2e366d8c7b2cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def run_model(reviews, tokenizer, model, device):\n",
    "    \n",
    "    batch_tokens = tokenizer(reviews[\"text\"], reviews[\"prompt\"], \n",
    "                             truncation='only_first', padding='max_length', max_length=256, return_tensors=\"pt\")\n",
    "    batch_tokens.to(device=device)\n",
    "    \n",
    "    masked_indexes = []\n",
    "\n",
    "    for tokens_input_ids in batch_tokens.data[\"input_ids\"]:\n",
    "\n",
    "        masked_index = torch.nonzero(tokens_input_ids == tokenizer.mask_token_id, as_tuple=False).item()\n",
    "        masked_indexes.append(masked_index)\n",
    "        \n",
    "    outputs = model(**batch_tokens)\n",
    "    \n",
    "    output_list = []\n",
    "    for i in range(len(outputs[\"logits\"])):\n",
    "        masked_index = masked_indexes[i]\n",
    "        output_list.append(outputs[\"logits\"][i][masked_index])\n",
    "    \n",
    "    return {\"logit_tensor\":output_list, \"prompt\": reviews[\"prompt\"], \"label\": reviews[\"label\"], \"text\": reviews[\"text\"]}\n",
    "\n",
    "model_output = prompt_dataset.map(\n",
    "    lambda e: run_model(e, tokenizer, model, cuda),\n",
    "    remove_columns=prompt_dataset.column_names,\n",
    "    batched=True, batch_size=4, num_proc=None)\n",
    "\n",
    "if validate_model:\n",
    "    model_output_val = prompt_dataset_val.map(\n",
    "        lambda e: run_model(e, tokenizer, model, cuda),\n",
    "        remove_columns=prompt_dataset.column_names,\n",
    "        batched=True, batch_size=4, num_proc=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression code adapted from : https://towardsdatascience.com/logistic-regression-on-mnist-with-pytorch-b048327f8d19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output.set_format(type='torch', columns=['logit_tensor', 'label'])\n",
    "dataloader = torch.utils.data.DataLoader(model_output, batch_size=32)\n",
    "\n",
    "if validate_model:\n",
    "    model_output_val.set_format(type='torch', columns=['logit_tensor', 'label'])\n",
    "    dataloader_val = torch.utils.data.DataLoader(model_output_val, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "input_dim = 30522\n",
    "output_dim = 3\n",
    "lr_rate = 0.0001\n",
    "\n",
    "LR_model = LogisticRegression(input_dim, output_dim)\n",
    "LR_model.to(device=cuda)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(LR_model.parameters(), lr=lr_rate)\n",
    "\n",
    "for epoch in range(int(epochs)):\n",
    "    for batch in dataloader:\n",
    "        \n",
    "        logit_tensors = batch[\"logit_tensor\"]\n",
    "        logit_tensors = logit_tensors.float().to(device=cuda)\n",
    "        \n",
    "        labels = batch[\"label\"]\n",
    "        labels = labels.to(device=cuda)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = LR_model(logit_tensors)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if validate_model:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_val in dataloader_val:\n",
    "\n",
    "            logit_tensors = batch_val[\"logit_tensor\"]\n",
    "            logit_tensors = logit_tensors.float().to(device=cuda)\n",
    "\n",
    "            labels = batch_val[\"label\"]\n",
    "            labeles = labels.to(device=cuda)\n",
    "\n",
    "            outputs = LR_model(logit_tensors)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total+= labels.size(0)\n",
    "            # for gpu, bring the predicted and labels back to cpu for python operations to work\n",
    "            predicted = predicted.to(device=\"cpu\")\n",
    "            labels = labels.to(device=\"cpu\")\n",
    "\n",
    "\n",
    "            correct+= (predicted == labels).sum()\n",
    "        accuracy = 100 * correct/total\n",
    "        print(\"Epoch: {}. Loss: {}. Validation Accuracy: {}.\".format(epoch, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LR_model.state_dict(), \"logit_models/\" + model_name + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
