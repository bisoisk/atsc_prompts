{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval template for MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "\n",
    "torch.cuda.is_available()\n",
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-uncased\", cache_dir='../bert_base_cache')\n",
    "model = transformers.AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\", cache_dir='../bert_base_cache')\n",
    "\n",
    "model = model.to(device=cuda)\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading SemEval Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9b6d847dca00ea02\n",
      "Reusing dataset sem_eval2014_task4_dataset (../dataset_cache\\sem_eval2014_task4_dataset\\default-9b6d847dca00ea02\\0.0.1\\f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aspect': 'Boot time', 'sentiment': 0, 'text': 'Boot time is super fast, around anywhere from 35 seconds to 1 minute.'}\n"
     ]
    }
   ],
   "source": [
    "semeval_laptop = datasets.load_dataset(\n",
    "    '../dataset_scripts/semeval2014_task4/semeval2014_task4.py',\n",
    "    data_files={\n",
    "        'test': r'dataset_files\\semeval_2014\\Laptops_Test_Gold.xml',\n",
    "        'train': r'dataset_files\\semeval_2014\\Laptop_Train_v2.xml'\n",
    "    },\n",
    "    cache_dir='../dataset_cache')\n",
    "\n",
    "semeval_laptop = semeval_laptop[\"test\"]\n",
    "print(semeval_laptop[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually created Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompts = [\n",
    "    \"The {aspect} is [MASK].\",\n",
    "    \"I [MASK] the {aspect}.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding prompts to review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prompts(reviews, prompts):\n",
    "\n",
    "    texts = []\n",
    "    sentiments = []\n",
    "    ids = []\n",
    "    aspect_prompts = []\n",
    "    \n",
    "    for i in range(len(reviews[\"aspect\"])):\n",
    "        \n",
    "        aspect = reviews[\"aspect\"][i]\n",
    "        text = reviews[\"text\"][i]\n",
    "        sentiment = reviews[\"sentiment\"][i]\n",
    "        \n",
    "        review_id = str(uuid.uuid1())\n",
    "        \n",
    "        for p in prompts:\n",
    "            aspect_prompt = p.format(aspect=aspect)\n",
    "\n",
    "            texts.append(text)\n",
    "            sentiments.append(sentiment)\n",
    "            ids.append(review_id)\n",
    "            aspect_prompts.append(aspect_prompt)\n",
    "\n",
    "    return {\"text\":texts, \"prompt\": aspect_prompts, \"label\": sentiments, \"review_aspect_id\": ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d07baeb58914b898b42a42698a5486c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'label': 0, 'prompt': 'The Boot time is [MASK].', 'review_aspect_id': '6d5fd487-8224-11eb-b3ea-7085c2c04498', 'text': 'Boot time is super fast, around anywhere from 35 seconds to 1 minute.'}\n",
      "1276\n"
     ]
    }
   ],
   "source": [
    "prompt_dataset = semeval_laptop.map(\n",
    "    lambda e: add_prompts(e, sentiment_prompts),\n",
    "    remove_columns=semeval_laptop.column_names,\n",
    "    batched=True)\n",
    "\n",
    "print(prompt_dataset[0])\n",
    "print(len(prompt_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(reviews, tokenizer, model, device):\n",
    "    \n",
    "    batch_tokens = tokenizer(reviews[\"text\"], reviews[\"prompt\"], \n",
    "                             truncation='only_first', padding='max_length', max_length=256, return_tensors=\"pt\")\n",
    "    batch_tokens.to(device=device)\n",
    "    \n",
    "    masked_indexes = []\n",
    "\n",
    "    for tokens_input_ids in batch_tokens.data[\"input_ids\"]:\n",
    "\n",
    "        masked_index = torch.nonzero(tokens_input_ids == tokenizer.mask_token_id, as_tuple=False).item()\n",
    "        masked_indexes.append(masked_index)\n",
    "        \n",
    "    outputs = model(**batch_tokens)\n",
    "    \n",
    "    output_list = []\n",
    "    for i in range(len(outputs[\"logits\"])):\n",
    "        masked_index = masked_indexes[i]\n",
    "        output_list.append(outputs[\"logits\"][i][masked_index])\n",
    "    \n",
    "    return {\"logit_tensor\":output_list, \"label\": reviews[\"label\"], \"review_aspect_id\": reviews[\"review_aspect_id\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59d365a414f459fa71bb131da7a59e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=638.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_output = prompt_dataset.map(\n",
    "    lambda e: run_model(e, tokenizer, model, cuda),\n",
    "    remove_columns=prompt_dataset.column_names,\n",
    "    batched=True, batch_size=2, num_proc=None)\n",
    "\n",
    "#print(len(model_output[\"logit_tensor\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Logistic Regression on mask logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d848cc08bd47788d33f1de815f8676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs\n",
    "\n",
    "LR_model = LogisticRegression(30522, 3)\n",
    "LR_model.load_state_dict(torch.load(\"logit_models/MLM_BERT-Base_Trained_on_Restaurant.pt\"))\n",
    "LR_model.eval()\n",
    "LR_model.to(device=cuda)\n",
    "\n",
    "def run_LR(example, LR_model, device):\n",
    "    logit_tensors = torch.FloatTensor(example[\"logit_tensor\"]).to(device=device)\n",
    "    class_probs = LR_model(logit_tensors)\n",
    "    class_probs_list = []\n",
    "    \n",
    "    for p in class_probs:\n",
    "        class_probs_list.append(p)\n",
    "    return {\"class_probs\": class_probs_list, \"label\": example[\"label\"], \"review_aspect_id\": example[\"review_aspect_id\"]}\n",
    "\n",
    "LR_output = model_output.map(\n",
    "    lambda e: run_LR(e, LR_model, cuda),\n",
    "    remove_columns=model_output.column_names,\n",
    "    batched=True, batch_size=32, num_proc=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert prompt class probs to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38df5541c02431f868ba421b56404aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=638.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def make_predictions(example, device):\n",
    "    ids = example[\"review_aspect_id\"]\n",
    "    labels = example[\"label\"]\n",
    "    for a in ids:\n",
    "        for b in ids:\n",
    "            assert a == b\n",
    "            \n",
    "    for a in labels:\n",
    "        for b in labels:\n",
    "            assert a == b\n",
    "            \n",
    "    class_probs = torch.FloatTensor(example[\"class_probs\"])\n",
    "    prediction_mean = torch.mean(class_probs, 0)\n",
    "    prediction = torch.argmax(prediction_mean)\n",
    "    \n",
    "    return {\"prediction\": [prediction], \"label\": [example[\"label\"][0]], \"review_aspect_id\": [example[\"review_aspect_id\"][0]]}\n",
    "\n",
    "predictions = LR_output.map(\n",
    "    lambda e: make_predictions(e, cuda),\n",
    "    remove_columns=LR_output.column_names,\n",
    "    batched=True, batch_size=len(sentiment_prompts), num_proc=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6802507836990596\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for pred in predictions:\n",
    "    total += 1\n",
    "    if pred[\"prediction\"] == pred[\"label\"]:\n",
    "        correct += 1\n",
    "        \n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
