{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval template for MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "\n",
    "torch.cuda.is_available()\n",
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-uncased\", cache_dir='../bert_base_cache')\n",
    "model = transformers.AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\", cache_dir='../bert_base_cache')\n",
    "\n",
    "model = model.to(device=cuda)\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading SemEval Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b5c3bb350489de8a\n",
      "Reusing dataset sem_eval2014_task4_dataset (../dataset_cache\\sem_eval2014_task4_dataset\\default-b5c3bb350489de8a\\0.0.1\\f33ba7108331ad17be3f9fb710ca001edb383fba797c6ed0938354e6812ca969)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aspect': 'cord', 'sentiment': 2, 'text': 'I charge it at night and skip taking the cord with me because of the good battery life.'}\n"
     ]
    }
   ],
   "source": [
    "semeval_laptop = datasets.load_dataset(\n",
    "    '../dataset_scripts/semeval2014_task4/semeval2014_task4.py',\n",
    "    data_files={\n",
    "        'train': '../dataset_files/semeval_2014/Laptops_Test_Gold.xml',\n",
    "        'test': '../dataset_files/semeval_2014/Laptop_Train_v2.xml'\n",
    "    },\n",
    "    cache_dir='../dataset_cache')\n",
    "\n",
    "semeval_laptop = semeval_laptop[\"test\"]\n",
    "print(semeval_laptop[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually created Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompts = [\n",
    "    \"The {aspect} is [MASK].\",\n",
    "    \"I [MASK] the {aspect}.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding prompts to review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prompts(reviews, prompts):\n",
    "\n",
    "    texts = []\n",
    "    sentiments = []\n",
    "    ids = []\n",
    "    aspect_prompts = []\n",
    "    \n",
    "    for i in range(len(reviews[\"aspect\"])):\n",
    "        \n",
    "        aspect = reviews[\"aspect\"][i]\n",
    "        text = reviews[\"text\"][i]\n",
    "        sentiment = reviews[\"sentiment\"][i]\n",
    "        \n",
    "        review_id = str(uuid.uuid1())\n",
    "        \n",
    "        for p in prompts:\n",
    "            aspect_prompt = p.format(aspect=aspect)\n",
    "\n",
    "            texts.append(text)\n",
    "            sentiments.append(sentiment)\n",
    "            ids.append(review_id)\n",
    "            aspect_prompts.append(aspect_prompt)\n",
    "\n",
    "    return {\"text\":texts, \"prompt\": aspect_prompts, \"label\": sentiments, \"review_id\": ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148a917e2257451faf90ba6037e76619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'label': 2, 'prompt': 'The cord is [MASK].', 'review_id': '6866a59d-813d-11eb-b122-7085c2c04498', 'text': 'I charge it at night and skip taking the cord with me because of the good battery life.'}\n",
      "4626\n"
     ]
    }
   ],
   "source": [
    "prompt_dataset = semeval_laptop.map(\n",
    "    lambda e: add_prompts(e, sentiment_prompts),\n",
    "    remove_columns=semeval_laptop.column_names,\n",
    "    batched=True)\n",
    "\n",
    "print(prompt_dataset[0])\n",
    "print(len(prompt_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Ron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(reviews, tokenizer, model, device):\n",
    "    \n",
    "    batch_tokens = tokenizer(reviews[\"text\"], reviews[\"prompt\"], \n",
    "                             truncation='only_first', padding='max_length', max_length=256, return_tensors=\"pt\")\n",
    "    batch_tokens.to(device=device)\n",
    "    \n",
    "    masked_indexes = []\n",
    "\n",
    "    for tokens_input_ids in batch_tokens.data[\"input_ids\"]:\n",
    "\n",
    "        masked_index = torch.nonzero(tokens_input_ids == tokenizer.mask_token_id, as_tuple=False).item()\n",
    "        masked_indexes.append(masked_index)\n",
    "        \n",
    "    outputs = model(**batch_tokens)\n",
    "    \n",
    "    output_list = []\n",
    "    for i in range(len(outputs[\"logits\"])):\n",
    "        masked_index = masked_indexes[i]\n",
    "        output_list.append(outputs[\"logits\"][i][masked_index])\n",
    "    \n",
    "    return {\"logit_tensor\":output_list, \"prompt\": reviews[\"prompt\"], \"label\": reviews[\"label\"], \"text\": reviews[\"text\"]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa13565e4814d0c9fa128ddba7929c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_output = prompt_dataset.map(\n",
    "    lambda e: run_model(e, tokenizer, model, cuda),\n",
    "    remove_columns=prompt_dataset.column_names,\n",
    "    batched=True, batch_size=2, num_proc=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model_output[\"logit_tensor\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
