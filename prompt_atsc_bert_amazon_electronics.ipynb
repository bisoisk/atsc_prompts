{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf3lVTZYhbzA"
   },
   "source": [
    "# Initial Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ORFXeezn5Og"
   },
   "source": [
    "## (Google Colab use only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3248,
     "status": "ok",
     "timestamp": 1615611015518,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "YFAQ6IgXn8FK",
    "outputId": "4d729be0-e1bd-49d7-fb79-e0dc9ecd5004"
   },
   "outputs": [],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    %cd '/content/drive/My Drive/zero_shot_atsc'\n",
    "    \n",
    "    # Install packages specified in requirements\n",
    "    !pip install -r requirements.txt\n",
    "    \n",
    "    # List the directory contents\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgzsHF7Zhbzo"
   },
   "source": [
    "## Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3240,
     "status": "ok",
     "timestamp": 1615611015520,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "DUpGBmOJhbzs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# We will use the following string ID to identify this particular (training) experiments\n",
    "# in directory paths and other settings\n",
    "experiment_id = 'prompt_lr_atsc_bert_amazon_electronics'\n",
    "\n",
    "# Random seed\n",
    "random_seed = 696\n",
    "\n",
    "# path to pretrained MLM model folder or the string \"bert-base-uncased\"\n",
    "mlm_model_path = os.path.join(\n",
    "    'progress', 'lm_further_pretraining_bert_amazon_electronics_bseoh_2021-03-06--18_59_53',\n",
    "    'results', 'checkpoint-1180388')\n",
    "\n",
    "# Proportion to be reserved for validation\n",
    "validation_dataset_proportion = 0.2\n",
    "\n",
    "# Prompts to be added to the end of each review text\n",
    "sentiment_prompts = [\n",
    "    \"The {aspect} is [MASK].\",\n",
    "    \"I [MASK] the {aspect}.\",\n",
    "    \"I felt the {aspect} was [MASK]\",\n",
    "    \"The {aspect} made me feel [MASK]\"]\n",
    "\n",
    "# Training settings for logistic regression head\n",
    "lr_training_epochs = 10\n",
    "lr_training_batch_size = 32\n",
    "lr_training_learning_rate = 1e-3\n",
    "lr_validation_batch_size = 32\n",
    "lr_testing_batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYZesqTioMvF"
   },
   "source": [
    "## Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4413,
     "status": "ok",
     "timestamp": 1615611016702,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "MlK_-DrWhbzb",
    "outputId": "0c766524-94c1-4a8c-c96f-5588fae1a30a"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "# Random seed settings\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Print version information\n",
    "print(\"Python version: \" + sys.version)\n",
    "print(\"NumPy version: \" + np.__version__)\n",
    "print(\"PyTorch version: \" + torch.__version__)\n",
    "print(\"Transformers version: \" + transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWuR30eUoTWP"
   },
   "source": [
    "## PyTorch GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4404,
     "status": "ok",
     "timestamp": 1615611016703,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "PfNlm-ykoSlM",
    "outputId": "19313593-1ecf-443d-d742-1746309d2a59"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    torch_device = torch.device('cuda')\n",
    "\n",
    "    # Set this to True to make your output immediately reproducible\n",
    "    # Note: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    \n",
    "    # Disable 'benchmark' mode: Set this False if you want to measure running times more fairly\n",
    "    # Note: https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # Faster Host to GPU copies with page-locked memory\n",
    "    use_pin_memory = True\n",
    "    \n",
    "    # Number of compute devices to be used for training\n",
    "    training_device_count = torch.cuda.device_count()\n",
    "\n",
    "    # CUDA libraries version information\n",
    "    print(\"CUDA Version: \" + str(torch.version.cuda))\n",
    "    print(\"cuDNN Version: \" + str(torch.backends.cudnn.version()))\n",
    "    print(\"CUDA Device Name: \" + str(torch.cuda.get_device_name()))\n",
    "    print(\"CUDA Capabilities: \"+ str(torch.cuda.get_device_capability()))\n",
    "    print(\"Number of CUDA devices: \"+ str(training_device_count))\n",
    "    \n",
    "else:\n",
    "    torch_device = torch.device('cpu')\n",
    "    use_pin_memory = False\n",
    "    \n",
    "    # Number of compute devices to be used for training\n",
    "    training_device_count = 1\n",
    "\n",
    "print()\n",
    "print(\"PyTorch device selected:\", torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayX5VRLfocFk"
   },
   "source": [
    "# Prepare Datasets for Prompt-based Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9LAAJP-hbz7"
   },
   "source": [
    "## Load the SemEval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4396,
     "status": "ok",
     "timestamp": 1615611016704,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "gpL2uHPUhbz9",
    "outputId": "a74d60b3-7c13-454e-9cd3-755695c68cf9"
   },
   "outputs": [],
   "source": [
    "# Load semeval for both domains\n",
    "in_domain_semeval_dataset = datasets.load_dataset(\n",
    "    os.path.abspath('dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
    "    data_files={\n",
    "        'test': 'dataset_files/semeval_2014/Laptops_Test_Gold.xml',\n",
    "        'train': 'dataset_files/semeval_2014/Laptop_Train_v2.xml',\n",
    "    },\n",
    "    cache_dir='dataset_cache')\n",
    "\n",
    "\n",
    "out_domain_semeval_dataset = datasets.load_dataset(\n",
    "    os.path.abspath('dataset_scripts/semeval2014_task4/semeval2014_task4.py'),\n",
    "    data_files={\n",
    "        'test': 'dataset_files/semeval_2014/Restaurants_Test_Gold.xml',\n",
    "        'train': 'dataset_files/semeval_2014/Restaurants_Train_v2.xml',\n",
    "    },\n",
    "    cache_dir='dataset_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4390,
     "status": "ok",
     "timestamp": 1615611016705,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Gi5m8AbPj1iJ"
   },
   "outputs": [],
   "source": [
    "out_domain_train = out_domain_semeval_dataset['train']\n",
    "out_domain_test = out_domain_semeval_dataset['test']\n",
    "\n",
    "in_domain_test = in_domain_semeval_dataset['test'] # Never use in-domain training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMYo7VeGM7D_"
   },
   "source": [
    "## Train-validation split for out-domain SemEval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4600,
     "status": "ok",
     "timestamp": 1615611016922,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "zy6FAEIaM6yd",
    "outputId": "3156faaf-896b-4cf1-c95a-859288becac4"
   },
   "outputs": [],
   "source": [
    "# Training set size after validation split\n",
    "new_out_domain_train_dataset_size = int(len(out_domain_train) * (1 - validation_dataset_proportion))\n",
    "new_out_domain_valid_dataset_size = len(out_domain_train) - new_out_domain_train_dataset_size\n",
    "\n",
    "print(\"Training dataset (out-domain) after split:\", new_out_domain_train_dataset_size)\n",
    "print(\"Validation dataset (out-domain) after split:\", new_out_domain_valid_dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4594,
     "status": "ok",
     "timestamp": 1615611016923,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "HDJivbzTR_oo",
    "outputId": "a9829e68-d662-4406-8d8c-4476fd515d31"
   },
   "outputs": [],
   "source": [
    "out_domain_train = out_domain_train.shuffle(seed=random_seed)\n",
    "\n",
    "new_out_domain_train_dataset = out_domain_train.select(\n",
    "    indices=np.arange(new_out_domain_train_dataset_size))\n",
    "new_out_domain_valid_dataset = out_domain_train.select(\n",
    "    indices=np.arange(\n",
    "        new_out_domain_train_dataset_size,\n",
    "        new_out_domain_train_dataset_size + new_out_domain_valid_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4585,
     "status": "ok",
     "timestamp": 1615611016925,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Tu7xUHpGkzCm",
    "outputId": "24b21180-28e6-42cd-fa94-c0bdce52b108"
   },
   "outputs": [],
   "source": [
    "print(new_out_domain_train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TOMmAtIvoZ_"
   },
   "source": [
    "# Zero-shot ATSC with Prompts + Logistic Regression Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jNAtuv-hbzv"
   },
   "source": [
    "## Load the pretrained LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8935,
     "status": "ok",
     "timestamp": 1615611021281,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "En2BmfjVhbzy"
   },
   "outputs": [],
   "source": [
    "# Load pretrained language model\n",
    "mlm = transformers.AutoModelForMaskedLM.from_pretrained(mlm_model_path)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased', cache_dir='bert_base_cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEIbN5Xthb0o"
   },
   "source": [
    "## Define a new model with logistic regression head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12172,
     "status": "ok",
     "timestamp": 1615611024526,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "wN3q4Rsopxby"
   },
   "outputs": [],
   "source": [
    "classifier_model = utils.MultiPromptSentimentClassificationHead(\n",
    "    mlm=mlm,\n",
    "    num_class=3, num_prompts=len(sentiment_prompts), mask_token_id=tokenizer.mask_token_id)\n",
    "\n",
    "# Freeze the MLM main layer\n",
    "for param in classifier_model.mlm.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier_model = classifier_model.to(device=torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEgP9H6dvo1p"
   },
   "source": [
    "## Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12177,
     "status": "ok",
     "timestamp": 1615611024535,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "W6i5tPiAhb0u"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    new_out_domain_train_dataset, batch_size=lr_training_batch_size,\n",
    "    pin_memory=use_pin_memory)\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    new_out_domain_valid_dataset, batch_size=lr_validation_batch_size,\n",
    "    pin_memory=use_pin_memory)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = transformers.AdamW(classifier_model.parameters(), lr=lr_training_learning_rate)\n",
    "\n",
    "# The directory to save the best version of the head\n",
    "trained_model_directory = os.path.join('.', 'trained_models', experiment_id)\n",
    "\n",
    "shutil.rmtree(trained_model_directory, ignore_errors=True)\n",
    "os.makedirs(trained_model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12175,
     "status": "ok",
     "timestamp": 1615611024538,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "0S80DoYrqApi"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, labels):\n",
    "    preds = predictions.argmax(-1)\n",
    "\n",
    "    precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
    "        y_true=labels, y_pred=preds, labels=[0,1,2], average='macro')\n",
    "\n",
    "    acc = sklearn.metrics.accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-3NkBKjpuO1"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479,
     "referenced_widgets": [
      "93c002a2fabe49b19f66d1d05df4c15d",
      "b5400ef754ed429f8ba7f6a2165dc942",
      "0ebf73763e1647e8a0ae8ce274cf2661",
      "459b7e472fa34f3da25a8a2fe56a7b94",
      "4a210665ac5949c5a5acaaeb44319f53",
      "561a0ee9a7524112b49ba8258d50caa9",
      "b0595732dc1345e79f57c2c1505f3980",
      "dbb3a2f84a2240a5a55d1c76c1a446a5",
      "3c35dcc5197540fe830b77e4e37020d0",
      "063adad8591640a89d0bd9c3b2d80981",
      "1c5179f6addc4e0cb86ac386198204c3",
      "e83b25175ea8499097f2bd45cd7f0249",
      "2c806e15e250402abec4a780142cb938",
      "cbee80ff8a264b0aba8a40f186ab8b8a",
      "f97fa1f90b744a049c2b00071ed25f05",
      "4284dd2296334e1ab9fe5fdb1f67d13c"
     ]
    },
    "executionInfo": {
     "elapsed": 109748,
     "status": "error",
     "timestamp": 1615611122121,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "8uIwk07Rhb0w",
    "outputId": "1540753e-6632-4927-8a7b-7683cb795f84"
   },
   "outputs": [],
   "source": [
    "training_progress_bar = tqdm.notebook.tqdm(range(int(lr_training_epochs)))\n",
    "\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for epoch in training_progress_bar:\n",
    "\n",
    "    print(\"Training epoch %d\" % epoch)\n",
    "    print()\n",
    "\n",
    "    classifier_model.train()\n",
    "\n",
    "    for batch in tqdm.notebook.tqdm(train_dataloader):\n",
    "\n",
    "        reviews_repeated = []\n",
    "        prompts_populated = []\n",
    "\n",
    "        for prompt in sentiment_prompts:\n",
    "            reviews_repeated = reviews_repeated + batch[\"text\"]\n",
    "\n",
    "            for aspect in batch[\"aspect\"]:\n",
    "                prompts_populated.append(prompt.format(aspect=aspect))\n",
    "\n",
    "        batch_encoded = tokenizer(\n",
    "            reviews_repeated, prompts_populated,\n",
    "            padding='max_length', truncation='only_first', max_length=256,\n",
    "            return_tensors='pt')\n",
    "        \n",
    "        batch_encoded = batch_encoded.to(torch_device)\n",
    "\n",
    "        labels = batch[\"sentiment\"]\n",
    "        labels = labels.to(torch_device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = classifier_model(batch_encoded)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validate the model using val dataset\n",
    "    classifier_model.eval()\n",
    "\n",
    "    print(\"Validation epoch %d\" % epoch)\n",
    "    print()\n",
    "\n",
    "    predictions_val = torch.Tensor([])\n",
    "    labels_val = torch.Tensor([])\n",
    "\n",
    "    for batch_val in tqdm.notebook.tqdm(validation_dataloader):\n",
    "\n",
    "        reviews_repeated = []\n",
    "        prompts_populated = []\n",
    "\n",
    "        for prompt in sentiment_prompts:\n",
    "            reviews_repeated = reviews_repeated + batch_val[\"text\"]\n",
    "\n",
    "            for aspect in batch_val[\"aspect\"]:\n",
    "                prompts_populated.append(prompt.format(aspect=aspect))\n",
    "\n",
    "        batch_encoded = tokenizer(\n",
    "            reviews_repeated, prompts_populated,\n",
    "            padding='max_length', truncation='only_first', max_length=256,\n",
    "            return_tensors='pt')\n",
    "        \n",
    "        batch_encoded.to(torch_device)\n",
    "\n",
    "        labels = batch_val[\"sentiment\"]\n",
    "\n",
    "        outputs = classifier_model(batch_encoded)\n",
    "\n",
    "        outputs = outputs.to('cpu')\n",
    "\n",
    "        predictions_val = torch.cat([predictions_val, outputs])\n",
    "        labels_val = torch.cat([labels_val, labels])\n",
    "    \n",
    "    # Compute metrics\n",
    "    validation_loss = torch.nn.functional.cross_entropy(predictions_val, labels_val.long())\n",
    "    validation_metrics = compute_metrics(predictions_val, labels_val)\n",
    "\n",
    "    print(\n",
    "        \"Epoch {}, Training Loss: {}, Validation Loss: {}, Validation Metrics: {}\".format(epoch, loss.item(), validation_loss.item(), validation_metrics))\n",
    "    print()\n",
    "\n",
    "    # Save the current epoch's model if the validation loss is lower than the best known so far\n",
    "    if validation_loss.item() < best_validation_loss:\n",
    "        best_validation_loss = validation_loss.item()\n",
    "        torch.save(classifier_model.linear, os.path.join(trained_model_directory, 'epoch_{}.pt'.format(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l1H_XIPhb0y"
   },
   "source": [
    "## Evaluation with in-domain test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 109733,
     "status": "aborted",
     "timestamp": 1615611122111,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "9NXoBTs5h2eO"
   },
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    in_domain_test, batch_size=lr_testing_batch_size,\n",
    "    pin_memory=use_pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 109730,
     "status": "aborted",
     "timestamp": 1615611122114,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "LLcc_wZjhb0y"
   },
   "outputs": [],
   "source": [
    "classifier_model.eval()\n",
    "\n",
    "predictions_test = torch.Tensor([])\n",
    "labels_test = torch.Tensor([])\n",
    "\n",
    "for batch_val in tqdm.notebook.tqdm(test_dataloader):\n",
    "\n",
    "    reviews_repeated = []\n",
    "    prompts_populated = []\n",
    "\n",
    "    for prompt in sentiment_prompts:\n",
    "        reviews_repeated = reviews_repeated + batch_val[\"text\"]\n",
    "\n",
    "        for aspect in batch_val[\"aspect\"]:\n",
    "            prompts_populated.append(prompt.format(aspect=aspect))\n",
    "\n",
    "    batch_encoded = tokenizer(\n",
    "        reviews_repeated, prompts_populated,\n",
    "        padding='max_length', truncation='only_first', max_length=256,\n",
    "        return_tensors='pt')\n",
    "    \n",
    "    batch_encoded.to(torch_device)\n",
    "\n",
    "    labels = batch_val[\"sentiment\"]\n",
    "\n",
    "    outputs = classifier_model(batch_encoded)\n",
    "\n",
    "    outputs = outputs.to('cpu')\n",
    "\n",
    "    predictions_test = torch.cat([predictions_test, outputs])\n",
    "    labels_test = torch.cat([labels_test, labels])\n",
    "\n",
    "# Compute metrics\n",
    "test_metrics = compute_metrics(predictions_test, labels_test)\n",
    "\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjpA_0m1hb08"
   },
   "source": [
    "## Results visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 109727,
     "status": "aborted",
     "timestamp": 1615611122116,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "w9G9AUeQhb09"
   },
   "outputs": [],
   "source": [
    "# Calculate metrics and confusion matrix based upon predictions and true labels\n",
    "cm = sklearn.metrics.confusion_matrix(labels_test, predictions_test)\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[i for i in [\"positive\", \"negative\", \"neutral\"]],\n",
    "    columns=[i for i in [\"positive\", \"negative\", \"neutral\"]])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "ax = sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "prompt_atsc_bert_amazon_electronics.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "063adad8591640a89d0bd9c3b2d80981": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ebf73763e1647e8a0ae8ce274cf2661": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_561a0ee9a7524112b49ba8258d50caa9",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a210665ac5949c5a5acaaeb44319f53",
      "value": 0
     }
    },
    "1c5179f6addc4e0cb86ac386198204c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 41%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbee80ff8a264b0aba8a40f186ab8b8a",
      "max": 91,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c806e15e250402abec4a780142cb938",
      "value": 37
     }
    },
    "2c806e15e250402abec4a780142cb938": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3c35dcc5197540fe830b77e4e37020d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c5179f6addc4e0cb86ac386198204c3",
       "IPY_MODEL_e83b25175ea8499097f2bd45cd7f0249"
      ],
      "layout": "IPY_MODEL_063adad8591640a89d0bd9c3b2d80981"
     }
    },
    "4284dd2296334e1ab9fe5fdb1f67d13c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "459b7e472fa34f3da25a8a2fe56a7b94": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbb3a2f84a2240a5a55d1c76c1a446a5",
      "placeholder": "​",
      "style": "IPY_MODEL_b0595732dc1345e79f57c2c1505f3980",
      "value": " 0/10 [01:37&lt;?, ?it/s]"
     }
    },
    "4a210665ac5949c5a5acaaeb44319f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "561a0ee9a7524112b49ba8258d50caa9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93c002a2fabe49b19f66d1d05df4c15d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ebf73763e1647e8a0ae8ce274cf2661",
       "IPY_MODEL_459b7e472fa34f3da25a8a2fe56a7b94"
      ],
      "layout": "IPY_MODEL_b5400ef754ed429f8ba7f6a2165dc942"
     }
    },
    "b0595732dc1345e79f57c2c1505f3980": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5400ef754ed429f8ba7f6a2165dc942": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbee80ff8a264b0aba8a40f186ab8b8a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbb3a2f84a2240a5a55d1c76c1a446a5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e83b25175ea8499097f2bd45cd7f0249": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4284dd2296334e1ab9fe5fdb1f67d13c",
      "placeholder": "​",
      "style": "IPY_MODEL_f97fa1f90b744a049c2b00071ed25f05",
      "value": " 37/91 [01:37&lt;02:20,  2.60s/it]"
     }
    },
    "f97fa1f90b744a049c2b00071ed25f05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
